{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uphKROdaubVc"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19494,
     "status": "ok",
     "timestamp": 1727249529680,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "nigCUKn8tcnt",
    "outputId": "1b036919-c84c-4c5d-f9ee-534e5803859b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For classification model\n",
    "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# For deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import shap\n",
    "\n",
    "# For post-processing algorithm\n",
    "# 'CalibratedEqOddsPostprocessing', 'RejectOptionClassification', 'EqOddsPostprocessing'\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing, RejectOptionClassification, EqOddsPostprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1727249532066,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "9NAdT4W0tuxB"
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"derived_df.csv\")\n",
    "\n",
    "# Drop the target variables of other papers\n",
    "target_vars = ['bmi_underweight', 'bmi_overweight', 'waist_circumference']\n",
    "######################################\n",
    "target_var = 'waist_circumference'\n",
    "######################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [\n",
    "    'education',\n",
    "    'state',\n",
    "    'region',\n",
    "    'religion',\n",
    "    'MPCE',\n",
    "    'working_status',\n",
    "    'occupation',\n",
    "    'caste',\n",
    "    'water',\n",
    "    'alcohol',\n",
    "    'activity1',\n",
    "    'benefit'\n",
    "    ]\n",
    "\n",
    "# Convert Type\n",
    "for col in data.columns:\n",
    "  if col in category_col:\n",
    "    data[col] = data[col].astype('category')\n",
    "  else:\n",
    "    data[col] = data[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_data = data.copy()\n",
    "# Drop the missing values\n",
    "used_data = used_data.dropna()\n",
    "# Define X and y\n",
    "X = used_data.drop(target_vars, axis=1)\n",
    "y = used_data[target_var]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "        'Overall': slice(None),\n",
    "        'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
    "        'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
    "        'General': X['caste'] == 'General',\n",
    "        'Other Backward Class': X['caste'] == 'Other backward class',\n",
    "        'MPCE 1': X['MPCE'] == 'Lowest',\n",
    "        'MPCE 2': X['MPCE'] == 'Lower middle',\n",
    "        'MPCE 3': X['MPCE'] == 'Middle',\n",
    "        'MPCE 4': X['MPCE'] == 'Upper middle',\n",
    "        'MPCE 5': X['MPCE'] == 'Highest',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define protected attributes\n",
    "protected_attributes = {\n",
    "    'caste2': ['Scheduled caste', 'Scheduled tribe', 'Other backward class'], # 'General'\n",
    "    'MPCE2': ['Lowest', 'Lower middle'] # 'Middle', 'Upper middle', 'Highest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: derive protected attributes\n",
    "def derive_protected_attributes(X, original_column, protected_attribute, protected_attributes):\n",
    "    binary_dataset = X.copy()\n",
    "    binary_dataset[protected_attribute] = binary_dataset[original_column].apply(\n",
    "        lambda x: 1 if x in protected_attributes[protected_attribute] else 0)\n",
    "    # drop the original column\n",
    "    binary_dataset = binary_dataset.drop(original_column, axis=1)\n",
    "    return binary_dataset\n",
    "\n",
    "# Derive protected attributes\n",
    "protect_caste_X = derive_protected_attributes(X, 'caste', 'caste2', protected_attributes)\n",
    "protect_MPCE_X = derive_protected_attributes(X, 'MPCE', 'MPCE2', protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
    "# X = X.drop(dummy_col, axis=1)\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_sd = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_sd, columns=X.columns, index=X.index)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category encoding\n",
    "protect_caste_X = pd.get_dummies(protect_caste_X, drop_first=True)\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
    "# protect_caste_X = protect_caste_X.drop(dummy_col, axis=1)\n",
    "protect_caste_X = protect_caste_X.astype('float32')\n",
    "protect_caste_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protect_caste_X_train, protect_caste_X_test, _, _ = train_test_split(protect_caste_X, y, test_size=0.2, random_state=42)\n",
    "protect_caste_X_train.shape, protect_caste_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category encoding\n",
    "protect_MPCE_X = pd.get_dummies(protect_MPCE_X, drop_first=True)\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
    "# protect_caste_X = protect_caste_X.drop(dummy_col, axis=1)\n",
    "protect_MPCE_X = protect_MPCE_X.astype('float32')\n",
    "protect_MPCE_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protect_MPCE_X_train, protect_MPCE_X_test, _, _ = train_test_split(protect_MPCE_X, y, test_size=0.2, random_state=42)\n",
    "protect_MPCE_X_train.shape, protect_MPCE_X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calibrated Equalized Odds Postprocessing (CEOP)\n",
    "2. Reject Option Classification (ROC)\n",
    "3. Equalized Odds Postprocessing (EOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing methods\n",
    "postprocessing_methods = [\n",
    "    'CalibratedEqOddsPostprocessing',\n",
    "    'RejectOptionClassification',\n",
    "    'EqOddsPostprocessing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Apply inprocessing method to the model\n",
    "def apply_postprocessing(method_name, unprivileged_groups, privileged_groups):\n",
    "    if method_name == 'CalibratedEqOddsPostprocessing':\n",
    "        postprocessor = CalibratedEqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                                       privileged_groups=privileged_groups)\n",
    "    elif method_name == 'RejectOptionClassification':\n",
    "        postprocessor = RejectOptionClassification(unprivileged_groups=unprivileged_groups,\n",
    "                                                  privileged_groups=privileged_groups)\n",
    "    elif method_name == 'EqOddsPostprocessing':\n",
    "        postprocessor = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid inprocessing method\")\n",
    "    return postprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Evaluate the model\n",
    "def calculate_metric(y_true, y_pred, y_pred_prob, metric_key):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate the metrics\n",
    "    ## Accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    ## Sensitivity and specificity\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    ## Equal opportunity, equalized odds, disparate impact\n",
    "    ### Equalized Odds: 根據真實標籤（0 或 1）計算錯誤率是否相等(tpr, fpr)\n",
    "    ### Demographic Parity: 預測為陽性的比例\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0    # True positive rate\n",
    "    fpr = fp / (fp + tn) if fp + tn > 0 else 0    # False positive rate\n",
    "    equal_opportunity = tpr\n",
    "    equalized_odds_tpr = tpr\n",
    "    equalized_odds_fpr = fpr\n",
    "    ppr = (tp + fp) / (tp + fp + tn + fn) if tp + fp + tn + fn > 0 else 0    # Predicted positive rate\n",
    "    disparate_impact = ppr\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'equal_opportunity': equal_opportunity,\n",
    "        'equalized_odds_tpr': equalized_odds_tpr,\n",
    "        'equalized_odds_fpr': equalized_odds_fpr,\n",
    "        'disparate_impact': disparate_impact\n",
    "    }\n",
    "\n",
    "    return metrics[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Train the model\n",
    "def model_fitted_post(method, model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups, protected_attribute, unprivileged_groups, privileged_groups):\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Train the model\n",
    "    if model_name in ['DNN', 'FCN']:\n",
    "        pipeline['model'].fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "        y_pred_prob = pipeline.predict(X_test).ravel()\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Create a BinaryLabelDataset\n",
    "    test_dataset = BinaryLabelDataset(\n",
    "        df=pd.DataFrame({'label': y_test, protected_attribute: X_test[protected_attribute]}),\n",
    "        label_names=['label'],\n",
    "        protected_attribute_names=[protected_attribute]\n",
    "    )\n",
    "    pred_dataset = test_dataset.copy()\n",
    "    pred_dataset.labels = (y_pred_prob >= 0.5).astype(int).reshape(-1, 1)\n",
    "    pred_dataset.scores = y_pred_prob.reshape(-1, 1)\n",
    "\n",
    "    # Apply postprocessing method\n",
    "    postprocessor = apply_postprocessing(method, unprivileged_groups, privileged_groups)\n",
    "    postprocessor.fit(test_dataset, pred_dataset)\n",
    "    transformed_dataset = postprocessor.predict(pred_dataset)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    results = pd.DataFrame()\n",
    "    for group_name, group_slice in groups.items():\n",
    "        # Create a Boolean mask for the group\n",
    "        group_mask = (\n",
    "            group_slice.loc[X_test.index]  # Use the group slice\n",
    "            if group_name != 'Overall'\n",
    "            else pd.Series(True, index=X_test.index)  \n",
    "        )\n",
    "\n",
    "        y_group = y_test[group_mask]\n",
    "        y_pred_group = transformed_dataset.labels[group_mask].ravel()\n",
    "        y_pred_prob_group = transformed_dataset.scores[group_mask].ravel()\n",
    "\n",
    "        for metric_key in metric_keys:\n",
    "            # Calculate the metric\n",
    "            metric_value = calculate_metric(y_group, y_pred_group, y_pred_prob_group, metric_key)\n",
    "            # Store the results\n",
    "            results.loc[group_name, metric_key] = metric_value\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the DNN model\n",
    "def create_dnn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
    "def create_fcn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'auc',\n",
    "    'sensitivity', 'specificity', \n",
    "    'equal_opportunity', 'equalized_odds_tpr', 'equalized_odds_fpr', 'disparate_impact'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    # 'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    # 'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    # 'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the models\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for protected_attribute in ['caste2', 'MPCE2']:\n",
    "    # Derive the dataset\n",
    "    if protected_attribute == 'caste2':\n",
    "        unprivileged_groups = [{'caste2': 1}]\n",
    "        privileged_groups = [{'caste2': 0}]\n",
    "        X_train = protect_caste_X_train\n",
    "        X_test = protect_caste_X_test\n",
    "    elif protected_attribute == 'MPCE2':\n",
    "        unprivileged_groups = [{'MPCE2': 1}]\n",
    "        privileged_groups = [{'MPCE2': 0}]\n",
    "        X_train = protect_MPCE_X_train\n",
    "        X_test = protect_MPCE_X_test\n",
    "\n",
    "    # Train and evaluate the models\n",
    "    for method in postprocessing_methods:\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Training {model_name} with {method} for {protected_attribute}\")\n",
    "            model_results = model_fitted_post(method, model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups, protected_attribute, unprivileged_groups, privileged_groups)\n",
    "            model_results['model'] = model_name\n",
    "            model_results['method'] = method\n",
    "            model_results['protected_attribute'] = protected_attribute\n",
    "            results = pd.concat([results, model_results], axis=0)\n",
    "\n",
    "# results.to_csv(f\"{target_var}\\\\postprocessing_results.csv\", index=True)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\postprocessing_results_LightGBM.csv\", index=True)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmAGw7t5BUD9GIxkZk2Q0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lasi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
