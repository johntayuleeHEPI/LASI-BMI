{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uphKROdaubVc"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19494,
     "status": "ok",
     "timestamp": 1727249529680,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "nigCUKn8tcnt",
    "outputId": "1b036919-c84c-4c5d-f9ee-534e5803859b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For classification model\n",
    "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# For deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1727249532066,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "9NAdT4W0tuxB"
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64867, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"derived_df.csv\")\n",
    "\n",
    "# Drop the target variables of other papers\n",
    "target_vars = ['bmi_underweight', 'bmi_overweight', 'waist_circumference']\n",
    "######################################\n",
    "target_var = 'waist_circumference'\n",
    "######################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [\n",
    "    'education',\n",
    "    'state',\n",
    "    'region',\n",
    "    'religion',\n",
    "    'MPCE',\n",
    "    'working_status',\n",
    "    'occupation',\n",
    "    'caste',\n",
    "    'water',\n",
    "    'alcohol',\n",
    "    'activity1',\n",
    "    'benefit'\n",
    "    ]\n",
    "\n",
    "# Convert Type\n",
    "for col in data.columns:\n",
    "  if col in category_col:\n",
    "    data[col] = data[col].astype('category')\n",
    "  else:\n",
    "    data[col] = data[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64867 entries, 0 to 64866\n",
      "Data columns (total 80 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   age                  64867 non-null  float64 \n",
      " 1   gender               64867 non-null  float64 \n",
      " 2   education            64866 non-null  category\n",
      " 3   migration            64770 non-null  float64 \n",
      " 4   state                64867 non-null  category\n",
      " 5   region               64867 non-null  category\n",
      " 6   residence            64867 non-null  float64 \n",
      " 7   religion             64867 non-null  category\n",
      " 8   martial_status       64865 non-null  float64 \n",
      " 9   living_alone         64867 non-null  float64 \n",
      " 10  MPCE                 64865 non-null  category\n",
      " 11  working_status       64852 non-null  category\n",
      " 12  occupation           64867 non-null  category\n",
      " 13  pension_amount       64867 non-null  float64 \n",
      " 14  retired              64774 non-null  float64 \n",
      " 15  pension              64812 non-null  float64 \n",
      " 16  caste                64770 non-null  category\n",
      " 17  hhsize               64867 non-null  float64 \n",
      " 18  hh_head_female       64867 non-null  float64 \n",
      " 19  water                64867 non-null  category\n",
      " 20  water_time           64867 non-null  float64 \n",
      " 21  home_ownership       63308 non-null  float64 \n",
      " 22  hypertension         64867 non-null  float64 \n",
      " 23  diabetes             64687 non-null  float64 \n",
      " 24  cancer               64696 non-null  float64 \n",
      " 25  chr_lung             64697 non-null  float64 \n",
      " 26  chr_heart            64697 non-null  float64 \n",
      " 27  stroke               64696 non-null  float64 \n",
      " 28  bone_joint           64698 non-null  float64 \n",
      " 29  psychiatric          64688 non-null  float64 \n",
      " 30  hi_chole             64696 non-null  float64 \n",
      " 31  chr_renal            64681 non-null  float64 \n",
      " 32  incontinence         64681 non-null  float64 \n",
      " 33  kidney               64681 non-null  float64 \n",
      " 34  BPH                  64680 non-null  float64 \n",
      " 35  influenza            64040 non-null  float64 \n",
      " 36  pneumococcal         64040 non-null  float64 \n",
      " 37  hepa_B               64040 non-null  float64 \n",
      " 38  typhoid              64040 non-null  float64 \n",
      " 39  dT                   64040 non-null  float64 \n",
      " 40  pain                 64644 non-null  float64 \n",
      " 41  sleep                64649 non-null  float64 \n",
      " 42  mlaria               64658 non-null  float64 \n",
      " 43  dengue               64658 non-null  float64 \n",
      " 44  chickungunya         64658 non-null  float64 \n",
      " 45  tuberculosis         64658 non-null  float64 \n",
      " 46  UTI                  64658 non-null  float64 \n",
      " 47  cog_score            64867 non-null  float64 \n",
      " 48  depression           64867 non-null  float64 \n",
      " 49  selfrated            64655 non-null  float64 \n",
      " 50  vision_self          64686 non-null  float64 \n",
      " 51  grip                 64185 non-null  float64 \n",
      " 52  aids                 64580 non-null  float64 \n",
      " 53  adl                  64587 non-null  float64 \n",
      " 54  iadl                 64541 non-null  float64 \n",
      " 55  denture              64580 non-null  float64 \n",
      " 56  smoking              64867 non-null  float64 \n",
      " 57  smokeless            64867 non-null  float64 \n",
      " 58  alcohol              64308 non-null  category\n",
      " 59  activity1            64867 non-null  category\n",
      " 60  activity2            64275 non-null  float64 \n",
      " 61  food_avail           64304 non-null  float64 \n",
      " 62  outpatient_care      64139 non-null  float64 \n",
      " 63  inpatient_care       64152 non-null  float64 \n",
      " 64  oop_outpatient       64867 non-null  float64 \n",
      " 65  oop_inpatient        64790 non-null  float64 \n",
      " 66  public_HI            64867 non-null  float64 \n",
      " 67  private_HI           64867 non-null  float64 \n",
      " 68  decision_role        64867 non-null  float64 \n",
      " 69  grandchildren        64867 non-null  float64 \n",
      " 70  provide_FS           64867 non-null  float64 \n",
      " 71  receive_FS           64867 non-null  float64 \n",
      " 72  family_unable        64867 non-null  float64 \n",
      " 73  organization_member  64867 non-null  float64 \n",
      " 74  discrimination       64867 non-null  float64 \n",
      " 75  life_satisfaction    63764 non-null  float64 \n",
      " 76  benefit              64867 non-null  category\n",
      " 77  bmi_underweight      59071 non-null  float64 \n",
      " 78  bmi_overweight       59071 non-null  float64 \n",
      " 79  waist_circumference  59048 non-null  float64 \n",
      "dtypes: category(12), float64(68)\n",
      "memory usage: 34.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55647, 77), (55647,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_data = data.copy()\n",
    "# Drop the missing values\n",
    "used_data = used_data.dropna()\n",
    "# Define X and y\n",
    "X = used_data.drop(target_vars, axis=1)\n",
    "y = used_data[target_var]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Evaluate the model\n",
    "def calculate_metric(y_true, y_pred, y_pred_prob, metric_key):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate the metrics\n",
    "    ## Accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    ## Sensitivity and specificity\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    ## Equal opportunity, equalized odds, disparate impact\n",
    "    ### Equalized Odds: 根據真實標籤（0 或 1）計算錯誤率是否相等(tpr, fpr)\n",
    "    ### Demographic Parity: 預測為陽性的比例\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0    # True positive rate\n",
    "    tnr = tn / (tn + fp) if tn + fp > 0 else 0    # True negative rate\n",
    "    equal_opportunity = tpr\n",
    "    equalized_odds = tpr + tnr\n",
    "    ppr = (tp + fp) / (tp + fp + tn + fn) if tp + fp + tn + fn > 0 else 0    # Predicted positive rate\n",
    "    disparate_impact = ppr\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'equal_opportunity': equal_opportunity,\n",
    "        'equalized_odds': equalized_odds,\n",
    "        'disparate_impact': disparate_impact\n",
    "    }\n",
    "\n",
    "    return metrics[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Train the model\n",
    "def model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups):\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Train the model\n",
    "    if model_name in ['DNN', 'FCN']:\n",
    "        pipeline['model'].fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "        y_pred_prob = pipeline.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    # Calculate the metrics\n",
    "    results = pd.DataFrame()\n",
    "    for group_name, group_slice in groups.items():\n",
    "        # Create a Boolean mask for the group\n",
    "        group_mask = (\n",
    "            group_slice.loc[X_test.index]  # Use the group slice\n",
    "            if group_name != 'Overall'\n",
    "            else pd.Series(True, index=X_test.index)  \n",
    "        )\n",
    "\n",
    "        y_group = y_test[group_mask]\n",
    "        y_pred_group = y_pred[group_mask]\n",
    "        y_pred_prob_group = y_pred_prob[group_mask]\n",
    "        \n",
    "        for metric_key in metric_keys:\n",
    "            # Calculate the metric\n",
    "            metric_value = calculate_metric(y_group, y_pred_group, y_pred_prob_group, metric_key)\n",
    "            # Store the results\n",
    "            results.loc[group_name, metric_key] = metric_value\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the DNN model\n",
    "def create_dnn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
    "def create_fcn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5QAqXEpxKBe"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Gradient Boosting\n",
    "5. LightGBM\n",
    "6. DNN\n",
    "7. FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'auc',\n",
    "    'sensitivity', 'specificity', \n",
    "    'equal_opportunity', 'equalized_odds', 'disparate_impact'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': None,\n",
    "    'FCN': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'Overall': slice(None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caste Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data splits\n",
    "data_splits = {\n",
    "    'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
    "    'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
    "    'General': X['caste'] == 'General',\n",
    "    'Other Backward Class': X['caste'] == 'Other backward class',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training Random Forest on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training XGBoost on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training Gradient Boosting on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training LightGBM on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training DNN on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training Random Forest on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training XGBoost on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training Gradient Boosting on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training LightGBM on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training DNN on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on General...\n",
      "(15346, 129) (15346,)\n",
      "Training Random Forest on General...\n",
      "(15346, 129) (15346,)\n",
      "Training XGBoost on General...\n",
      "(15346, 129) (15346,)\n",
      "Training Gradient Boosting on General...\n",
      "(15346, 129) (15346,)\n",
      "Training LightGBM on General...\n",
      "(15346, 129) (15346,)\n",
      "Training DNN on General...\n",
      "(15346, 129) (15346,)\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on General...\n",
      "(15346, 129) (15346,)\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training Random Forest on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training XGBoost on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training Gradient Boosting on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training LightGBM on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training DNN on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training FCN on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>Model</th>\n",
       "      <th>Subgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.770876</td>\n",
       "      <td>0.701826</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.605954</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.888213</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>1.421341</td>\n",
       "      <td>0.251018</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.762729</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.555344</td>\n",
       "      <td>0.817878</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.917871</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>1.366253</td>\n",
       "      <td>0.203157</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.740326</td>\n",
       "      <td>0.634951</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.801399</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.857034</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>1.360886</td>\n",
       "      <td>0.262220</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.778004</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.836621</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.901901</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>1.428866</td>\n",
       "      <td>0.239817</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.769857</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.822664</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.885171</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>1.421381</td>\n",
       "      <td>0.254073</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.736762</td>\n",
       "      <td>0.618280</td>\n",
       "      <td>0.531587</td>\n",
       "      <td>0.571665</td>\n",
       "      <td>0.768307</td>\n",
       "      <td>0.531587</td>\n",
       "      <td>0.838023</td>\n",
       "      <td>0.531587</td>\n",
       "      <td>1.369610</td>\n",
       "      <td>0.284114</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.715886</td>\n",
       "      <td>0.576728</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.753434</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.809125</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>1.336090</td>\n",
       "      <td>0.301935</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.745609</td>\n",
       "      <td>0.706920</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.685526</td>\n",
       "      <td>0.816724</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>1.468309</td>\n",
       "      <td>0.392230</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730176</td>\n",
       "      <td>0.706587</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.650586</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>1.423978</td>\n",
       "      <td>0.355508</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.687671</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.663582</td>\n",
       "      <td>0.791105</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.791971</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>1.433095</td>\n",
       "      <td>0.388505</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.744545</td>\n",
       "      <td>0.717986</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.675237</td>\n",
       "      <td>0.816381</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>1.458460</td>\n",
       "      <td>0.369878</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730176</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.664016</td>\n",
       "      <td>0.808879</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.794708</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>1.434555</td>\n",
       "      <td>0.386376</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.704630</td>\n",
       "      <td>0.645780</td>\n",
       "      <td>0.644955</td>\n",
       "      <td>0.645367</td>\n",
       "      <td>0.767515</td>\n",
       "      <td>0.644955</td>\n",
       "      <td>0.747263</td>\n",
       "      <td>0.644955</td>\n",
       "      <td>1.392218</td>\n",
       "      <td>0.416179</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.698244</td>\n",
       "      <td>0.640260</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>0.752943</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.747263</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>1.376892</td>\n",
       "      <td>0.409792</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.756352</td>\n",
       "      <td>0.779831</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.797947</td>\n",
       "      <td>0.830027</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>1.486497</td>\n",
       "      <td>0.616938</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.752769</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.792906</td>\n",
       "      <td>0.823299</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>1.483524</td>\n",
       "      <td>0.604886</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.738111</td>\n",
       "      <td>0.771939</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.666403</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>1.454566</td>\n",
       "      <td>0.601303</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.749511</td>\n",
       "      <td>0.780054</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.790063</td>\n",
       "      <td>0.829341</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.676704</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>1.477036</td>\n",
       "      <td>0.604235</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.755049</td>\n",
       "      <td>0.780851</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>0.827783</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>1.485481</td>\n",
       "      <td>0.612378</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.719218</td>\n",
       "      <td>0.766930</td>\n",
       "      <td>0.751659</td>\n",
       "      <td>0.759218</td>\n",
       "      <td>0.782299</td>\n",
       "      <td>0.751659</td>\n",
       "      <td>0.672742</td>\n",
       "      <td>0.751659</td>\n",
       "      <td>1.424401</td>\n",
       "      <td>0.577199</td>\n",
       "      <td>DNN</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.695440</td>\n",
       "      <td>0.742635</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.740782</td>\n",
       "      <td>0.752464</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>1.372060</td>\n",
       "      <td>0.585993</td>\n",
       "      <td>FCN</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.729557</td>\n",
       "      <td>0.713089</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.704787</td>\n",
       "      <td>0.814111</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.757951</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>1.454626</td>\n",
       "      <td>0.452714</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722683</td>\n",
       "      <td>0.722380</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.783569</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.435743</td>\n",
       "      <td>0.418346</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722446</td>\n",
       "      <td>0.713740</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.803884</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.768110</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>1.437675</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.725290</td>\n",
       "      <td>0.717963</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.808034</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.772527</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>1.443115</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.721258</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.700184</td>\n",
       "      <td>0.811339</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.772968</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>1.453275</td>\n",
       "      <td>0.437070</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.689974</td>\n",
       "      <td>0.676487</td>\n",
       "      <td>0.634271</td>\n",
       "      <td>0.654699</td>\n",
       "      <td>0.756576</td>\n",
       "      <td>0.634271</td>\n",
       "      <td>0.738074</td>\n",
       "      <td>0.634271</td>\n",
       "      <td>1.372345</td>\n",
       "      <td>0.434463</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.675990</td>\n",
       "      <td>0.652807</td>\n",
       "      <td>0.642455</td>\n",
       "      <td>0.647590</td>\n",
       "      <td>0.728817</td>\n",
       "      <td>0.642455</td>\n",
       "      <td>0.704947</td>\n",
       "      <td>0.642455</td>\n",
       "      <td>1.347402</td>\n",
       "      <td>0.456032</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision    recall        f1       auc  sensitivity  \\\n",
       "Overall  0.770876   0.701826  0.533128  0.605954  0.827184     0.533128   \n",
       "Overall  0.762729   0.729323  0.448382  0.555344  0.817878     0.448382   \n",
       "Overall  0.740326   0.634951  0.503852  0.561856  0.801399     0.503852   \n",
       "Overall  0.778004   0.726115  0.526965  0.610714  0.836621     0.526965   \n",
       "Overall  0.769857   0.697395  0.536210  0.606272  0.822664     0.536210   \n",
       "Overall  0.736762   0.618280  0.531587  0.571665  0.768307     0.531587   \n",
       "Overall  0.715886   0.576728  0.526965  0.550725  0.753434     0.526965   \n",
       "Overall  0.745609   0.706920  0.665390  0.685526  0.816724     0.665390   \n",
       "Overall  0.730176   0.706587  0.602810  0.650586  0.800400     0.602810   \n",
       "Overall  0.729111   0.687671  0.641124  0.663582  0.791105     0.641124   \n",
       "Overall  0.744545   0.717986  0.637292  0.675237  0.816381     0.637292   \n",
       "Overall  0.730176   0.690083  0.639847  0.664016  0.808879     0.639847   \n",
       "Overall  0.704630   0.645780  0.644955  0.645367  0.767515     0.644955   \n",
       "Overall  0.698244   0.640260  0.629630  0.634900  0.752943     0.629630   \n",
       "Overall  0.756352   0.779831  0.816925  0.797947  0.830027     0.816925   \n",
       "Overall  0.752769   0.782445  0.803650  0.792906  0.823299     0.803650   \n",
       "Overall  0.738111   0.771939  0.788164  0.779967  0.808238     0.788164   \n",
       "Overall  0.749511   0.780054  0.800332  0.790063  0.829341     0.800332   \n",
       "Overall  0.755049   0.780851  0.811947  0.796095  0.827783     0.811947   \n",
       "Overall  0.719218   0.766930  0.751659  0.759218  0.782299     0.751659   \n",
       "Overall  0.695440   0.742635  0.738938  0.740782  0.752464     0.738938   \n",
       "Overall  0.729557   0.713089  0.696675  0.704787  0.814111     0.696675   \n",
       "Overall  0.722683   0.722380  0.652174  0.685484  0.799270     0.652174   \n",
       "Overall  0.722446   0.713740  0.669565  0.690947  0.803884     0.669565   \n",
       "Overall  0.725290   0.717963  0.670588  0.693467  0.808034     0.670588   \n",
       "Overall  0.730031   0.721258  0.680307  0.700184  0.811339     0.680307   \n",
       "Overall  0.689974   0.676487  0.634271  0.654699  0.756576     0.634271   \n",
       "Overall  0.675990   0.652807  0.642455  0.647590  0.728817     0.642455   \n",
       "\n",
       "         specificity  equal_opportunity  equalized_odds  disparate_impact  \\\n",
       "Overall     0.888213           0.533128        1.421341          0.251018   \n",
       "Overall     0.917871           0.448382        1.366253          0.203157   \n",
       "Overall     0.857034           0.503852        1.360886          0.262220   \n",
       "Overall     0.901901           0.526965        1.428866          0.239817   \n",
       "Overall     0.885171           0.536210        1.421381          0.254073   \n",
       "Overall     0.838023           0.531587        1.369610          0.284114   \n",
       "Overall     0.809125           0.526965        1.336090          0.301935   \n",
       "Overall     0.802920           0.665390        1.468309          0.392230   \n",
       "Overall     0.821168           0.602810        1.423978          0.355508   \n",
       "Overall     0.791971           0.641124        1.433095          0.388505   \n",
       "Overall     0.821168           0.637292        1.458460          0.369878   \n",
       "Overall     0.794708           0.639847        1.434555          0.386376   \n",
       "Overall     0.747263           0.644955        1.392218          0.416179   \n",
       "Overall     0.747263           0.629630        1.376892          0.409792   \n",
       "Overall     0.669572           0.816925        1.486497          0.616938   \n",
       "Overall     0.679873           0.803650        1.483524          0.604886   \n",
       "Overall     0.666403           0.788164        1.454566          0.601303   \n",
       "Overall     0.676704           0.800332        1.477036          0.604235   \n",
       "Overall     0.673534           0.811947        1.485481          0.612378   \n",
       "Overall     0.672742           0.751659        1.424401          0.577199   \n",
       "Overall     0.633122           0.738938        1.372060          0.585993   \n",
       "Overall     0.757951           0.696675        1.454626          0.452714   \n",
       "Overall     0.783569           0.652174        1.435743          0.418346   \n",
       "Overall     0.768110           0.669565        1.437675          0.434700   \n",
       "Overall     0.772527           0.670588        1.443115          0.432804   \n",
       "Overall     0.772968           0.680307        1.453275          0.437070   \n",
       "Overall     0.738074           0.634271        1.372345          0.434463   \n",
       "Overall     0.704947           0.642455        1.347402          0.456032   \n",
       "\n",
       "                       Model              Subgroup  \n",
       "Overall  Logistic Regression       Scheduled Caste  \n",
       "Overall        Random Forest       Scheduled Caste  \n",
       "Overall              XGBoost       Scheduled Caste  \n",
       "Overall    Gradient Boosting       Scheduled Caste  \n",
       "Overall             LightGBM       Scheduled Caste  \n",
       "Overall                  DNN       Scheduled Caste  \n",
       "Overall                  FCN       Scheduled Caste  \n",
       "Overall  Logistic Regression       Scheduled Tribe  \n",
       "Overall        Random Forest       Scheduled Tribe  \n",
       "Overall              XGBoost       Scheduled Tribe  \n",
       "Overall    Gradient Boosting       Scheduled Tribe  \n",
       "Overall             LightGBM       Scheduled Tribe  \n",
       "Overall                  DNN       Scheduled Tribe  \n",
       "Overall                  FCN       Scheduled Tribe  \n",
       "Overall  Logistic Regression               General  \n",
       "Overall        Random Forest               General  \n",
       "Overall              XGBoost               General  \n",
       "Overall    Gradient Boosting               General  \n",
       "Overall             LightGBM               General  \n",
       "Overall                  DNN               General  \n",
       "Overall                  FCN               General  \n",
       "Overall  Logistic Regression  Other Backward Class  \n",
       "Overall        Random Forest  Other Backward Class  \n",
       "Overall              XGBoost  Other Backward Class  \n",
       "Overall    Gradient Boosting  Other Backward Class  \n",
       "Overall             LightGBM  Other Backward Class  \n",
       "Overall                  DNN  Other Backward Class  \n",
       "Overall                  FCN  Other Backward Class  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the data splits to train the models\n",
    "results = pd.DataFrame()\n",
    "for split_name, split_mask in data_splits.items():\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Training {model_name} on {split_name}...')\n",
    "        # Split the data\n",
    "        sub_X = X[split_mask]\n",
    "        sub_y = y[split_mask]\n",
    "        # Category encoding\n",
    "        sub_X = pd.get_dummies(sub_X, drop_first=True)\n",
    "        print(sub_X.shape, sub_y.shape)\n",
    "        # Convert to float32\n",
    "        sub_X = sub_X.astype('float32')\n",
    "        sub_y = sub_y.astype('float32')\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        sub_X_sd = scaler.fit_transform(sub_X)\n",
    "        sub_X = pd.DataFrame(sub_X_sd, columns=sub_X.columns, index=sub_X.index)\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(sub_X, sub_y, test_size=0.2, random_state=42)\n",
    "        # Train the model\n",
    "        if model_name in ['DNN', 'FCN']:\n",
    "            dim = X_train.shape[1]\n",
    "            model = create_dnn_model(dim) if model_name == 'DNN' else create_fcn_model(dim)\n",
    "        model_results = model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups)\n",
    "        model_results['Model'] = model_name\n",
    "        model_results['Subgroup'] = split_name\n",
    "        results = pd.concat([results, model_results], axis=0)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_subgroup_caste.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPCE Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data splits\n",
    "data_splits = {\n",
    "    'MPCE 1': used_data['MPCE'] == 'Lowest',\n",
    "    'MPCE 2': used_data['MPCE'] == 'Lower middle',\n",
    "    'MPCE 3': used_data['MPCE'] == 'Middle',\n",
    "    'MPCE 4': used_data['MPCE'] == 'Upper middle',\n",
    "    'MPCE 5': used_data['MPCE'] == 'Highest',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training Random Forest on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training XGBoost on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training Gradient Boosting on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training LightGBM on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training DNN on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training Random Forest on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training XGBoost on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training Gradient Boosting on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training LightGBM on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training DNN on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training Random Forest on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training XGBoost on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training Gradient Boosting on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training LightGBM on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training DNN on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Training FCN on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Training Logistic Regression on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training Random Forest on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training XGBoost on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training Gradient Boosting on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training LightGBM on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training DNN on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Training FCN on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training Random Forest on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training XGBoost on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training Gradient Boosting on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training LightGBM on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training DNN on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>Model</th>\n",
       "      <th>Subgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.789544</td>\n",
       "      <td>0.674952</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.597798</td>\n",
       "      <td>0.832553</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.893684</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>1.430158</td>\n",
       "      <td>0.231724</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.768720</td>\n",
       "      <td>0.661137</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.816576</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>1.334581</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.762960</td>\n",
       "      <td>0.614953</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551551</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.871169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.371169</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.782455</td>\n",
       "      <td>0.689342</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.553230</td>\n",
       "      <td>0.828296</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.914321</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>1.376328</td>\n",
       "      <td>0.195392</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.776252</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>0.820882</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.893058</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>1.385459</td>\n",
       "      <td>0.219318</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.762074</td>\n",
       "      <td>0.604853</td>\n",
       "      <td>0.530395</td>\n",
       "      <td>0.565182</td>\n",
       "      <td>0.776230</td>\n",
       "      <td>0.530395</td>\n",
       "      <td>0.857411</td>\n",
       "      <td>0.530395</td>\n",
       "      <td>1.387806</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.718210</td>\n",
       "      <td>0.516871</td>\n",
       "      <td>0.512158</td>\n",
       "      <td>0.514504</td>\n",
       "      <td>0.748890</td>\n",
       "      <td>0.512158</td>\n",
       "      <td>0.803002</td>\n",
       "      <td>0.512158</td>\n",
       "      <td>1.315160</td>\n",
       "      <td>0.288879</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.752541</td>\n",
       "      <td>0.707169</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.675174</td>\n",
       "      <td>0.812849</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.823054</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>1.469003</td>\n",
       "      <td>0.363677</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.737517</td>\n",
       "      <td>0.711724</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.794660</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.846549</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>1.419246</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722492</td>\n",
       "      <td>0.664260</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.637413</td>\n",
       "      <td>0.790058</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.795154</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>1.407807</td>\n",
       "      <td>0.367212</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.727756</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.662636</td>\n",
       "      <td>0.812256</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.849486</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>1.457699</td>\n",
       "      <td>0.332744</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.742819</td>\n",
       "      <td>0.698137</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.658851</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.821586</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>1.445337</td>\n",
       "      <td>0.355722</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.701281</td>\n",
       "      <td>0.627407</td>\n",
       "      <td>0.614872</td>\n",
       "      <td>0.621076</td>\n",
       "      <td>0.760009</td>\n",
       "      <td>0.614872</td>\n",
       "      <td>0.758443</td>\n",
       "      <td>0.614872</td>\n",
       "      <td>1.373316</td>\n",
       "      <td>0.390190</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.628370</td>\n",
       "      <td>0.594895</td>\n",
       "      <td>0.611174</td>\n",
       "      <td>0.751511</td>\n",
       "      <td>0.594895</td>\n",
       "      <td>0.767254</td>\n",
       "      <td>0.594895</td>\n",
       "      <td>1.362149</td>\n",
       "      <td>0.376933</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.717262</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.709519</td>\n",
       "      <td>0.812157</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.761506</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>1.463448</td>\n",
       "      <td>0.453034</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.728989</td>\n",
       "      <td>0.726405</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.694374</td>\n",
       "      <td>0.799578</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>1.449149</td>\n",
       "      <td>0.423820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.715506</td>\n",
       "      <td>0.700708</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.686478</td>\n",
       "      <td>0.784310</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.752301</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>1.425117</td>\n",
       "      <td>0.444494</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.732584</td>\n",
       "      <td>0.720365</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.705007</td>\n",
       "      <td>0.808389</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.769038</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>1.459329</td>\n",
       "      <td>0.443596</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.728090</td>\n",
       "      <td>0.713139</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.701529</td>\n",
       "      <td>0.804568</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.760669</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>1.450961</td>\n",
       "      <td>0.448090</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.694382</td>\n",
       "      <td>0.678937</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.661355</td>\n",
       "      <td>0.754823</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>0.737238</td>\n",
       "      <td>0.644660</td>\n",
       "      <td>1.381899</td>\n",
       "      <td>0.439551</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.687640</td>\n",
       "      <td>0.668342</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.656790</td>\n",
       "      <td>0.745713</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.645631</td>\n",
       "      <td>1.369480</td>\n",
       "      <td>0.447191</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.736931</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.748288</td>\n",
       "      <td>0.813252</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.704265</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.464265</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.714739</td>\n",
       "      <td>0.727909</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.725687</td>\n",
       "      <td>0.793215</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.705213</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>1.428692</td>\n",
       "      <td>0.518367</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.738865</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>1.452240</td>\n",
       "      <td>0.519274</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730612</td>\n",
       "      <td>0.739655</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.807455</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.713744</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>1.459831</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.737719</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.734498</td>\n",
       "      <td>0.799060</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>1.447892</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.697494</td>\n",
       "      <td>0.701739</td>\n",
       "      <td>0.699610</td>\n",
       "      <td>0.752753</td>\n",
       "      <td>0.701739</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.701739</td>\n",
       "      <td>1.369986</td>\n",
       "      <td>0.524717</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.686621</td>\n",
       "      <td>0.701847</td>\n",
       "      <td>0.693913</td>\n",
       "      <td>0.697857</td>\n",
       "      <td>0.749196</td>\n",
       "      <td>0.693913</td>\n",
       "      <td>0.678673</td>\n",
       "      <td>0.693913</td>\n",
       "      <td>1.372586</td>\n",
       "      <td>0.515646</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.743578</td>\n",
       "      <td>0.763288</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.793955</td>\n",
       "      <td>0.819932</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.619590</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>1.446779</td>\n",
       "      <td>0.647248</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.745413</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.795127</td>\n",
       "      <td>0.810982</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.624146</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>1.451335</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.727982</td>\n",
       "      <td>0.760088</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.798963</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.627563</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>1.423262</td>\n",
       "      <td>0.625229</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.744954</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.792692</td>\n",
       "      <td>0.822589</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.638952</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>1.455388</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.734862</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>0.814672</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.637813</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>1.438120</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.712385</td>\n",
       "      <td>0.753188</td>\n",
       "      <td>0.771121</td>\n",
       "      <td>0.762049</td>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.771121</td>\n",
       "      <td>0.625285</td>\n",
       "      <td>0.771121</td>\n",
       "      <td>1.396406</td>\n",
       "      <td>0.611468</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.729013</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>0.744361</td>\n",
       "      <td>0.735271</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>0.580866</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>1.341234</td>\n",
       "      <td>0.622936</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision    recall        f1       auc  sensitivity  \\\n",
       "Overall  0.789544   0.674952  0.536474  0.597798  0.832553     0.536474   \n",
       "Overall  0.768720   0.661137  0.424012  0.516667  0.816576     0.424012   \n",
       "Overall  0.762960   0.614953  0.500000  0.551551  0.797242     0.500000   \n",
       "Overall  0.782455   0.689342  0.462006  0.553230  0.828296     0.462006   \n",
       "Overall  0.776252   0.654545  0.492401  0.562012  0.820882     0.492401   \n",
       "Overall  0.762074   0.604853  0.530395  0.565182  0.776230     0.530395   \n",
       "Overall  0.718210   0.516871  0.512158  0.514504  0.748890     0.512158   \n",
       "Overall  0.752541   0.707169  0.645949  0.675174  0.812849     0.645949   \n",
       "Overall  0.737517   0.711724  0.572697  0.634686  0.794660     0.572697   \n",
       "Overall  0.722492   0.664260  0.612653  0.637413  0.790058     0.612653   \n",
       "Overall  0.753425   0.727756  0.608213  0.662636  0.812256     0.608213   \n",
       "Overall  0.742819   0.698137  0.623751  0.658851  0.807050     0.623751   \n",
       "Overall  0.701281   0.627407  0.614872  0.621076  0.760009     0.614872   \n",
       "Overall  0.698630   0.628370  0.594895  0.611174  0.751511     0.594895   \n",
       "Overall  0.733933   0.717262  0.701942  0.709519  0.812157     0.701942   \n",
       "Overall  0.728989   0.726405  0.665049  0.694374  0.799578     0.665049   \n",
       "Overall  0.715506   0.700708  0.672816  0.686478  0.784310     0.672816   \n",
       "Overall  0.732584   0.720365  0.690291  0.705007  0.808389     0.690291   \n",
       "Overall  0.728090   0.713139  0.690291  0.701529  0.804568     0.690291   \n",
       "Overall  0.694382   0.678937  0.644660  0.661355  0.754823     0.644660   \n",
       "Overall  0.687640   0.668342  0.645631  0.656790  0.745713     0.645631   \n",
       "Overall  0.733333   0.736931  0.760000  0.748288  0.813252     0.760000   \n",
       "Overall  0.714739   0.727909  0.723478  0.725687  0.793215     0.723478   \n",
       "Overall  0.726531   0.738865  0.735652  0.737255  0.794041     0.735652   \n",
       "Overall  0.730612   0.739655  0.746087  0.742857  0.807455     0.746087   \n",
       "Overall  0.724263   0.737719  0.731304  0.734498  0.799060     0.731304   \n",
       "Overall  0.685714   0.697494  0.701739  0.699610  0.752753     0.701739   \n",
       "Overall  0.686621   0.701847  0.693913  0.697857  0.749196     0.693913   \n",
       "Overall  0.743578   0.763288  0.827189  0.793955  0.819932     0.827189   \n",
       "Overall  0.745413   0.765458  0.827189  0.795127  0.810982     0.827189   \n",
       "Overall  0.727982   0.760088  0.795699  0.777486  0.798963     0.795699   \n",
       "Overall  0.744954   0.770290  0.816436  0.792692  0.822589     0.816436   \n",
       "Overall  0.734862   0.766176  0.800307  0.782870  0.814672     0.800307   \n",
       "Overall  0.712385   0.753188  0.771121  0.762049  0.774802     0.771121   \n",
       "Overall  0.688073   0.729013  0.760369  0.744361  0.735271     0.760369   \n",
       "\n",
       "         specificity  equal_opportunity  equalized_odds  disparate_impact  \\\n",
       "Overall     0.893684           0.536474        1.430158          0.231724   \n",
       "Overall     0.910569           0.424012        1.334581          0.186974   \n",
       "Overall     0.871169           0.500000        1.371169          0.237040   \n",
       "Overall     0.914321           0.462006        1.376328          0.195392   \n",
       "Overall     0.893058           0.492401        1.385459          0.219318   \n",
       "Overall     0.857411           0.530395        1.387806          0.255649   \n",
       "Overall     0.803002           0.512158        1.315160          0.288879   \n",
       "Overall     0.823054           0.645949        1.469003          0.363677   \n",
       "Overall     0.846549           0.572697        1.419246          0.320371   \n",
       "Overall     0.795154           0.612653        1.407807          0.367212   \n",
       "Overall     0.849486           0.608213        1.457699          0.332744   \n",
       "Overall     0.821586           0.623751        1.445337          0.355722   \n",
       "Overall     0.758443           0.614872        1.373316          0.390190   \n",
       "Overall     0.767254           0.594895        1.362149          0.376933   \n",
       "Overall     0.761506           0.701942        1.463448          0.453034   \n",
       "Overall     0.784100           0.665049        1.449149          0.423820   \n",
       "Overall     0.752301           0.672816        1.425117          0.444494   \n",
       "Overall     0.769038           0.690291        1.459329          0.443596   \n",
       "Overall     0.760669           0.690291        1.450961          0.448090   \n",
       "Overall     0.737238           0.644660        1.381899          0.439551   \n",
       "Overall     0.723849           0.645631        1.369480          0.447191   \n",
       "Overall     0.704265           0.760000        1.464265          0.537868   \n",
       "Overall     0.705213           0.723478        1.428692          0.518367   \n",
       "Overall     0.716588           0.735652        1.452240          0.519274   \n",
       "Overall     0.713744           0.746087        1.459831          0.526077   \n",
       "Overall     0.716588           0.731304        1.447892          0.517007   \n",
       "Overall     0.668246           0.701739        1.369986          0.524717   \n",
       "Overall     0.678673           0.693913        1.372586          0.515646   \n",
       "Overall     0.619590           0.827189        1.446779          0.647248   \n",
       "Overall     0.624146           0.827189        1.451335          0.645413   \n",
       "Overall     0.627563           0.795699        1.423262          0.625229   \n",
       "Overall     0.638952           0.816436        1.455388          0.633028   \n",
       "Overall     0.637813           0.800307        1.438120          0.623853   \n",
       "Overall     0.625285           0.771121        1.396406          0.611468   \n",
       "Overall     0.580866           0.760369        1.341234          0.622936   \n",
       "\n",
       "                       Model Subgroup  \n",
       "Overall  Logistic Regression   MPCE 1  \n",
       "Overall        Random Forest   MPCE 1  \n",
       "Overall              XGBoost   MPCE 1  \n",
       "Overall    Gradient Boosting   MPCE 1  \n",
       "Overall             LightGBM   MPCE 1  \n",
       "Overall                  DNN   MPCE 1  \n",
       "Overall                  FCN   MPCE 1  \n",
       "Overall  Logistic Regression   MPCE 2  \n",
       "Overall        Random Forest   MPCE 2  \n",
       "Overall              XGBoost   MPCE 2  \n",
       "Overall    Gradient Boosting   MPCE 2  \n",
       "Overall             LightGBM   MPCE 2  \n",
       "Overall                  DNN   MPCE 2  \n",
       "Overall                  FCN   MPCE 2  \n",
       "Overall  Logistic Regression   MPCE 3  \n",
       "Overall        Random Forest   MPCE 3  \n",
       "Overall              XGBoost   MPCE 3  \n",
       "Overall    Gradient Boosting   MPCE 3  \n",
       "Overall             LightGBM   MPCE 3  \n",
       "Overall                  DNN   MPCE 3  \n",
       "Overall                  FCN   MPCE 3  \n",
       "Overall  Logistic Regression   MPCE 4  \n",
       "Overall        Random Forest   MPCE 4  \n",
       "Overall              XGBoost   MPCE 4  \n",
       "Overall    Gradient Boosting   MPCE 4  \n",
       "Overall             LightGBM   MPCE 4  \n",
       "Overall                  DNN   MPCE 4  \n",
       "Overall                  FCN   MPCE 4  \n",
       "Overall  Logistic Regression   MPCE 5  \n",
       "Overall        Random Forest   MPCE 5  \n",
       "Overall              XGBoost   MPCE 5  \n",
       "Overall    Gradient Boosting   MPCE 5  \n",
       "Overall             LightGBM   MPCE 5  \n",
       "Overall                  DNN   MPCE 5  \n",
       "Overall                  FCN   MPCE 5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the data splits to train the models\n",
    "results = pd.DataFrame()\n",
    "for split_name, split_mask in data_splits.items():\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Training {model_name} on {split_name}...')\n",
    "        # Split the data\n",
    "        sub_X = X[split_mask]\n",
    "        sub_y = y[split_mask]\n",
    "        # Category encoding\n",
    "        sub_X = pd.get_dummies(sub_X, drop_first=True)\n",
    "        print(sub_X.shape, sub_y.shape)\n",
    "        # Convert to float32\n",
    "        sub_X = sub_X.astype('float32')\n",
    "        sub_y = sub_y.astype('float32')\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        sub_X_sd = scaler.fit_transform(sub_X)\n",
    "        sub_X = pd.DataFrame(sub_X_sd, columns=sub_X.columns, index=sub_X.index)\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(sub_X, sub_y, test_size=0.2, random_state=42)\n",
    "        # Train the model\n",
    "        if model_name in ['DNN', 'FCN']:\n",
    "            dim = X_train.shape[1]\n",
    "            model = create_dnn_model(dim) if model_name == 'DNN' else create_fcn_model(dim)\n",
    "        # Train the model\n",
    "        model_results = model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups)\n",
    "        model_results['Model'] = model_name\n",
    "        model_results['Subgroup'] = split_name\n",
    "        results = pd.concat([results, model_results], axis=0)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_subgroup_MPCE.csv\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmAGw7t5BUD9GIxkZk2Q0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lasi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
