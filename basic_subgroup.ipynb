{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uphKROdaubVc"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19494,
     "status": "ok",
     "timestamp": 1727249529680,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "nigCUKn8tcnt",
    "outputId": "1b036919-c84c-4c5d-f9ee-534e5803859b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For classification model\n",
    "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# For deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1727249532066,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "9NAdT4W0tuxB"
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64867, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"derived_df.csv\")\n",
    "\n",
    "# Drop the target variables of other papers\n",
    "target_vars = ['bmi_underweight', 'bmi_overweight', 'waist_circumference']\n",
    "######################################\n",
    "target_var = 'waist_circumference'\n",
    "######################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [\n",
    "    'education',\n",
    "    'state',\n",
    "    'region',\n",
    "    'religion',\n",
    "    'MPCE',\n",
    "    'working_status',\n",
    "    'occupation',\n",
    "    'caste',\n",
    "    'water',\n",
    "    'alcohol',\n",
    "    'activity1',\n",
    "    'benefit'\n",
    "    ]\n",
    "\n",
    "# Convert Type\n",
    "for col in data.columns:\n",
    "  if col in category_col:\n",
    "    data[col] = data[col].astype('category')\n",
    "  else:\n",
    "    data[col] = data[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64867 entries, 0 to 64866\n",
      "Data columns (total 80 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   age                  64867 non-null  float64 \n",
      " 1   gender               64867 non-null  float64 \n",
      " 2   education            64866 non-null  category\n",
      " 3   migration            64770 non-null  float64 \n",
      " 4   state                64867 non-null  category\n",
      " 5   region               64867 non-null  category\n",
      " 6   residence            64867 non-null  float64 \n",
      " 7   religion             64867 non-null  category\n",
      " 8   martial_status       64865 non-null  float64 \n",
      " 9   living_alone         64867 non-null  float64 \n",
      " 10  MPCE                 64865 non-null  category\n",
      " 11  working_status       64852 non-null  category\n",
      " 12  occupation           64867 non-null  category\n",
      " 13  pension_amount       64867 non-null  float64 \n",
      " 14  retired              64774 non-null  float64 \n",
      " 15  pension              64812 non-null  float64 \n",
      " 16  caste                64770 non-null  category\n",
      " 17  hhsize               64867 non-null  float64 \n",
      " 18  hh_head_female       64867 non-null  float64 \n",
      " 19  water                64867 non-null  category\n",
      " 20  water_time           64867 non-null  float64 \n",
      " 21  home_ownership       63308 non-null  float64 \n",
      " 22  hypertension         64867 non-null  float64 \n",
      " 23  diabetes             64687 non-null  float64 \n",
      " 24  cancer               64696 non-null  float64 \n",
      " 25  chr_lung             64697 non-null  float64 \n",
      " 26  chr_heart            64697 non-null  float64 \n",
      " 27  stroke               64696 non-null  float64 \n",
      " 28  bone_joint           64698 non-null  float64 \n",
      " 29  psychiatric          64688 non-null  float64 \n",
      " 30  hi_chole             64696 non-null  float64 \n",
      " 31  chr_renal            64681 non-null  float64 \n",
      " 32  incontinence         64681 non-null  float64 \n",
      " 33  kidney               64681 non-null  float64 \n",
      " 34  BPH                  64680 non-null  float64 \n",
      " 35  influenza            64040 non-null  float64 \n",
      " 36  pneumococcal         64040 non-null  float64 \n",
      " 37  hepa_B               64040 non-null  float64 \n",
      " 38  typhoid              64040 non-null  float64 \n",
      " 39  dT                   64040 non-null  float64 \n",
      " 40  pain                 64644 non-null  float64 \n",
      " 41  sleep                64649 non-null  float64 \n",
      " 42  mlaria               64658 non-null  float64 \n",
      " 43  dengue               64658 non-null  float64 \n",
      " 44  chickungunya         64658 non-null  float64 \n",
      " 45  tuberculosis         64658 non-null  float64 \n",
      " 46  UTI                  64658 non-null  float64 \n",
      " 47  cog_score            64867 non-null  float64 \n",
      " 48  depression           64867 non-null  float64 \n",
      " 49  selfrated            64655 non-null  float64 \n",
      " 50  vision_self          64686 non-null  float64 \n",
      " 51  grip                 64185 non-null  float64 \n",
      " 52  aids                 64580 non-null  float64 \n",
      " 53  adl                  64587 non-null  float64 \n",
      " 54  iadl                 64541 non-null  float64 \n",
      " 55  denture              64580 non-null  float64 \n",
      " 56  smoking              64867 non-null  float64 \n",
      " 57  smokeless            64867 non-null  float64 \n",
      " 58  alcohol              64308 non-null  category\n",
      " 59  activity1            64867 non-null  category\n",
      " 60  activity2            64275 non-null  float64 \n",
      " 61  food_avail           64304 non-null  float64 \n",
      " 62  outpatient_care      64139 non-null  float64 \n",
      " 63  inpatient_care       64152 non-null  float64 \n",
      " 64  oop_outpatient       64867 non-null  float64 \n",
      " 65  oop_inpatient        64790 non-null  float64 \n",
      " 66  public_HI            64867 non-null  float64 \n",
      " 67  private_HI           64867 non-null  float64 \n",
      " 68  decision_role        64867 non-null  float64 \n",
      " 69  grandchildren        64867 non-null  float64 \n",
      " 70  provide_FS           64867 non-null  float64 \n",
      " 71  receive_FS           64867 non-null  float64 \n",
      " 72  family_unable        64867 non-null  float64 \n",
      " 73  organization_member  64867 non-null  float64 \n",
      " 74  discrimination       64867 non-null  float64 \n",
      " 75  life_satisfaction    63764 non-null  float64 \n",
      " 76  benefit              64867 non-null  category\n",
      " 77  bmi_underweight      59071 non-null  float64 \n",
      " 78  bmi_overweight       59071 non-null  float64 \n",
      " 79  waist_circumference  59048 non-null  float64 \n",
      "dtypes: category(12), float64(68)\n",
      "memory usage: 34.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55647, 77), (55647,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_data = data.copy()\n",
    "# Drop the missing values\n",
    "used_data = used_data.dropna()\n",
    "# Define X and y\n",
    "X = used_data.drop(target_vars, axis=1)\n",
    "y = used_data[target_var]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Evaluate the model\n",
    "def calculate_metric(y_true, y_pred, y_pred_prob, metric_key):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate the metrics\n",
    "    ## Accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    ## Sensitivity and specificity\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    ## Equal opportunity, equalized odds, disparate impact\n",
    "    ### Equalized Odds: 根據真實標籤（0 或 1）計算錯誤率是否相等(tpr, fpr)\n",
    "    ### Demographic Parity: 預測為陽性的比例\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0    # True positive rate\n",
    "    fpr = fp / (fp + tn) if fp + tn > 0 else 0    # False positive rate\n",
    "    equal_opportunity = tpr\n",
    "    equalized_odds_tpr = tpr\n",
    "    equalized_odds_fpr = fpr\n",
    "    ppr = (tp + fp) / (tp + fp + tn + fn) if tp + fp + tn + fn > 0 else 0    # Predicted positive rate\n",
    "    disparate_impact = ppr\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'equal_opportunity': equal_opportunity,\n",
    "        'equalized_odds_tpr': equalized_odds_tpr,\n",
    "        'equalized_odds_fpr': equalized_odds_fpr,\n",
    "        'disparate_impact': disparate_impact\n",
    "    }\n",
    "\n",
    "    return metrics[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Train the model\n",
    "def model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups):\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Train the model\n",
    "    if model_name in ['DNN', 'FCN']:\n",
    "        pipeline['model'].fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "        y_pred_prob = pipeline.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    # Calculate the metrics\n",
    "    results = pd.DataFrame()\n",
    "    for group_name, group_slice in groups.items():\n",
    "        # Create a Boolean mask for the group\n",
    "        group_mask = (\n",
    "            group_slice.loc[X_test.index]  # Use the group slice\n",
    "            if group_name != 'Overall'\n",
    "            else pd.Series(True, index=X_test.index)  \n",
    "        )\n",
    "\n",
    "        y_group = y_test[group_mask]\n",
    "        y_pred_group = y_pred[group_mask]\n",
    "        y_pred_prob_group = y_pred_prob[group_mask]\n",
    "        \n",
    "        for metric_key in metric_keys:\n",
    "            # Calculate the metric\n",
    "            metric_value = calculate_metric(y_group, y_pred_group, y_pred_prob_group, metric_key)\n",
    "            # Store the results\n",
    "            results.loc[group_name, metric_key] = metric_value\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the DNN model\n",
    "def create_dnn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
    "def create_fcn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5QAqXEpxKBe"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Gradient Boosting\n",
    "5. LightGBM\n",
    "6. DNN\n",
    "7. FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'auc',\n",
    "    'sensitivity', 'specificity', \n",
    "    'equal_opportunity', 'equalized_odds_tpr', 'equalized_odds_fpr', 'disparate_impact'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': None,\n",
    "    'FCN': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    'Overall': slice(None)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caste Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data splits\n",
    "data_splits = {\n",
    "    'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
    "    'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
    "    'General': X['caste'] == 'General',\n",
    "    'Other Backward Class': X['caste'] == 'Other backward class',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training Random Forest on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training XGBoost on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training Gradient Boosting on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training LightGBM on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "Training DNN on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on Scheduled Caste...\n",
      "(9817, 129) (9817,)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Training Logistic Regression on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training Random Forest on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training XGBoost on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training Gradient Boosting on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training LightGBM on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "Training DNN on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training FCN on Scheduled Tribe...\n",
      "(9393, 129) (9393,)\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Training Logistic Regression on General...\n",
      "(15346, 129) (15346,)\n",
      "Training Random Forest on General...\n",
      "(15346, 129) (15346,)\n",
      "Training XGBoost on General...\n",
      "(15346, 129) (15346,)\n",
      "Training Gradient Boosting on General...\n",
      "(15346, 129) (15346,)\n",
      "Training LightGBM on General...\n",
      "(15346, 129) (15346,)\n",
      "Training DNN on General...\n",
      "(15346, 129) (15346,)\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training FCN on General...\n",
      "(15346, 129) (15346,)\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training Random Forest on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training XGBoost on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training Gradient Boosting on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training LightGBM on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "Training DNN on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training FCN on Other Backward Class...\n",
      "(21091, 129) (21091,)\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds_tpr</th>\n",
       "      <th>equalized_odds_fpr</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>Model</th>\n",
       "      <th>Subgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.770876</td>\n",
       "      <td>0.701826</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.605954</td>\n",
       "      <td>0.827184</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.888213</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.111787</td>\n",
       "      <td>0.251018</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.762729</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.555344</td>\n",
       "      <td>0.817878</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.917871</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.448382</td>\n",
       "      <td>0.082129</td>\n",
       "      <td>0.203157</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.740326</td>\n",
       "      <td>0.634951</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.801399</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.857034</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.503852</td>\n",
       "      <td>0.142966</td>\n",
       "      <td>0.262220</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.778004</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.610714</td>\n",
       "      <td>0.836621</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.901901</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.098099</td>\n",
       "      <td>0.239817</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.769857</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.822664</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.885171</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.114829</td>\n",
       "      <td>0.254073</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.734216</td>\n",
       "      <td>0.600954</td>\n",
       "      <td>0.582435</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.770068</td>\n",
       "      <td>0.582435</td>\n",
       "      <td>0.809125</td>\n",
       "      <td>0.582435</td>\n",
       "      <td>0.582435</td>\n",
       "      <td>0.190875</td>\n",
       "      <td>0.320265</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.718941</td>\n",
       "      <td>0.582064</td>\n",
       "      <td>0.530046</td>\n",
       "      <td>0.554839</td>\n",
       "      <td>0.748317</td>\n",
       "      <td>0.530046</td>\n",
       "      <td>0.812167</td>\n",
       "      <td>0.530046</td>\n",
       "      <td>0.530046</td>\n",
       "      <td>0.187833</td>\n",
       "      <td>0.300916</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Scheduled Caste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.745609</td>\n",
       "      <td>0.706920</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.685526</td>\n",
       "      <td>0.816724</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.802920</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.665390</td>\n",
       "      <td>0.197080</td>\n",
       "      <td>0.392230</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730176</td>\n",
       "      <td>0.706587</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.650586</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.602810</td>\n",
       "      <td>0.178832</td>\n",
       "      <td>0.355508</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.729111</td>\n",
       "      <td>0.687671</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.663582</td>\n",
       "      <td>0.791105</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.791971</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.641124</td>\n",
       "      <td>0.208029</td>\n",
       "      <td>0.388505</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.744545</td>\n",
       "      <td>0.717986</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.675237</td>\n",
       "      <td>0.816381</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.821168</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.637292</td>\n",
       "      <td>0.178832</td>\n",
       "      <td>0.369878</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730176</td>\n",
       "      <td>0.690083</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.664016</td>\n",
       "      <td>0.808879</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.794708</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.205292</td>\n",
       "      <td>0.386376</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.701969</td>\n",
       "      <td>0.652531</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.630119</td>\n",
       "      <td>0.763768</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.768248</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.231752</td>\n",
       "      <td>0.389037</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.672166</td>\n",
       "      <td>0.609724</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.601036</td>\n",
       "      <td>0.742107</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.729015</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.270985</td>\n",
       "      <td>0.405003</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Scheduled Tribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.756352</td>\n",
       "      <td>0.779831</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.797947</td>\n",
       "      <td>0.830027</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.816925</td>\n",
       "      <td>0.330428</td>\n",
       "      <td>0.616938</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.752769</td>\n",
       "      <td>0.782445</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.792906</td>\n",
       "      <td>0.823299</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.679873</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.803650</td>\n",
       "      <td>0.320127</td>\n",
       "      <td>0.604886</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.738111</td>\n",
       "      <td>0.771939</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.779967</td>\n",
       "      <td>0.808238</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.666403</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.788164</td>\n",
       "      <td>0.333597</td>\n",
       "      <td>0.601303</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.749511</td>\n",
       "      <td>0.780054</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.790063</td>\n",
       "      <td>0.829341</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.676704</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.800332</td>\n",
       "      <td>0.323296</td>\n",
       "      <td>0.604235</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.755049</td>\n",
       "      <td>0.780851</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.796095</td>\n",
       "      <td>0.827783</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.673534</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.811947</td>\n",
       "      <td>0.326466</td>\n",
       "      <td>0.612378</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.719870</td>\n",
       "      <td>0.765993</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.760446</td>\n",
       "      <td>0.784774</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.669572</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.754978</td>\n",
       "      <td>0.330428</td>\n",
       "      <td>0.580456</td>\n",
       "      <td>DNN</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.691205</td>\n",
       "      <td>0.726554</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.744199</td>\n",
       "      <td>0.745830</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.588748</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.762721</td>\n",
       "      <td>0.411252</td>\n",
       "      <td>0.618241</td>\n",
       "      <td>FCN</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.729557</td>\n",
       "      <td>0.713089</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.704787</td>\n",
       "      <td>0.814111</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.757951</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.242049</td>\n",
       "      <td>0.452714</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722683</td>\n",
       "      <td>0.722380</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.799270</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.783569</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.216431</td>\n",
       "      <td>0.418346</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722446</td>\n",
       "      <td>0.713740</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.803884</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.768110</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.231890</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.725290</td>\n",
       "      <td>0.717963</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.693467</td>\n",
       "      <td>0.808034</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.772527</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.227473</td>\n",
       "      <td>0.432804</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730031</td>\n",
       "      <td>0.721258</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.700184</td>\n",
       "      <td>0.811339</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.772968</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.680307</td>\n",
       "      <td>0.227032</td>\n",
       "      <td>0.437070</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.692818</td>\n",
       "      <td>0.689477</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.649161</td>\n",
       "      <td>0.760770</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.761484</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.238516</td>\n",
       "      <td>0.412183</td>\n",
       "      <td>DNN</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.670775</td>\n",
       "      <td>0.647242</td>\n",
       "      <td>0.636317</td>\n",
       "      <td>0.641733</td>\n",
       "      <td>0.726513</td>\n",
       "      <td>0.636317</td>\n",
       "      <td>0.700530</td>\n",
       "      <td>0.636317</td>\n",
       "      <td>0.636317</td>\n",
       "      <td>0.299470</td>\n",
       "      <td>0.455558</td>\n",
       "      <td>FCN</td>\n",
       "      <td>Other Backward Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision    recall        f1       auc  sensitivity  \\\n",
       "Overall  0.770876   0.701826  0.533128  0.605954  0.827184     0.533128   \n",
       "Overall  0.762729   0.729323  0.448382  0.555344  0.817878     0.448382   \n",
       "Overall  0.740326   0.634951  0.503852  0.561856  0.801399     0.503852   \n",
       "Overall  0.778004   0.726115  0.526965  0.610714  0.836621     0.526965   \n",
       "Overall  0.769857   0.697395  0.536210  0.606272  0.822664     0.536210   \n",
       "Overall  0.734216   0.600954  0.582435  0.591549  0.770068     0.582435   \n",
       "Overall  0.718941   0.582064  0.530046  0.554839  0.748317     0.530046   \n",
       "Overall  0.745609   0.706920  0.665390  0.685526  0.816724     0.665390   \n",
       "Overall  0.730176   0.706587  0.602810  0.650586  0.800400     0.602810   \n",
       "Overall  0.729111   0.687671  0.641124  0.663582  0.791105     0.641124   \n",
       "Overall  0.744545   0.717986  0.637292  0.675237  0.816381     0.637292   \n",
       "Overall  0.730176   0.690083  0.639847  0.664016  0.808879     0.639847   \n",
       "Overall  0.701969   0.652531  0.609195  0.630119  0.763768     0.609195   \n",
       "Overall  0.672166   0.609724  0.592593  0.601036  0.742107     0.592593   \n",
       "Overall  0.756352   0.779831  0.816925  0.797947  0.830027     0.816925   \n",
       "Overall  0.752769   0.782445  0.803650  0.792906  0.823299     0.803650   \n",
       "Overall  0.738111   0.771939  0.788164  0.779967  0.808238     0.788164   \n",
       "Overall  0.749511   0.780054  0.800332  0.790063  0.829341     0.800332   \n",
       "Overall  0.755049   0.780851  0.811947  0.796095  0.827783     0.811947   \n",
       "Overall  0.719870   0.765993  0.754978  0.760446  0.784774     0.754978   \n",
       "Overall  0.691205   0.726554  0.762721  0.744199  0.745830     0.762721   \n",
       "Overall  0.729557   0.713089  0.696675  0.704787  0.814111     0.696675   \n",
       "Overall  0.722683   0.722380  0.652174  0.685484  0.799270     0.652174   \n",
       "Overall  0.722446   0.713740  0.669565  0.690947  0.803884     0.669565   \n",
       "Overall  0.725290   0.717963  0.670588  0.693467  0.808034     0.670588   \n",
       "Overall  0.730031   0.721258  0.680307  0.700184  0.811339     0.680307   \n",
       "Overall  0.692818   0.689477  0.613299  0.649161  0.760770     0.613299   \n",
       "Overall  0.670775   0.647242  0.636317  0.641733  0.726513     0.636317   \n",
       "\n",
       "         specificity  equal_opportunity  equalized_odds_tpr  \\\n",
       "Overall     0.888213           0.533128            0.533128   \n",
       "Overall     0.917871           0.448382            0.448382   \n",
       "Overall     0.857034           0.503852            0.503852   \n",
       "Overall     0.901901           0.526965            0.526965   \n",
       "Overall     0.885171           0.536210            0.536210   \n",
       "Overall     0.809125           0.582435            0.582435   \n",
       "Overall     0.812167           0.530046            0.530046   \n",
       "Overall     0.802920           0.665390            0.665390   \n",
       "Overall     0.821168           0.602810            0.602810   \n",
       "Overall     0.791971           0.641124            0.641124   \n",
       "Overall     0.821168           0.637292            0.637292   \n",
       "Overall     0.794708           0.639847            0.639847   \n",
       "Overall     0.768248           0.609195            0.609195   \n",
       "Overall     0.729015           0.592593            0.592593   \n",
       "Overall     0.669572           0.816925            0.816925   \n",
       "Overall     0.679873           0.803650            0.803650   \n",
       "Overall     0.666403           0.788164            0.788164   \n",
       "Overall     0.676704           0.800332            0.800332   \n",
       "Overall     0.673534           0.811947            0.811947   \n",
       "Overall     0.669572           0.754978            0.754978   \n",
       "Overall     0.588748           0.762721            0.762721   \n",
       "Overall     0.757951           0.696675            0.696675   \n",
       "Overall     0.783569           0.652174            0.652174   \n",
       "Overall     0.768110           0.669565            0.669565   \n",
       "Overall     0.772527           0.670588            0.670588   \n",
       "Overall     0.772968           0.680307            0.680307   \n",
       "Overall     0.761484           0.613299            0.613299   \n",
       "Overall     0.700530           0.636317            0.636317   \n",
       "\n",
       "         equalized_odds_fpr  disparate_impact                Model  \\\n",
       "Overall            0.111787          0.251018  Logistic Regression   \n",
       "Overall            0.082129          0.203157        Random Forest   \n",
       "Overall            0.142966          0.262220              XGBoost   \n",
       "Overall            0.098099          0.239817    Gradient Boosting   \n",
       "Overall            0.114829          0.254073             LightGBM   \n",
       "Overall            0.190875          0.320265                  DNN   \n",
       "Overall            0.187833          0.300916                  FCN   \n",
       "Overall            0.197080          0.392230  Logistic Regression   \n",
       "Overall            0.178832          0.355508        Random Forest   \n",
       "Overall            0.208029          0.388505              XGBoost   \n",
       "Overall            0.178832          0.369878    Gradient Boosting   \n",
       "Overall            0.205292          0.386376             LightGBM   \n",
       "Overall            0.231752          0.389037                  DNN   \n",
       "Overall            0.270985          0.405003                  FCN   \n",
       "Overall            0.330428          0.616938  Logistic Regression   \n",
       "Overall            0.320127          0.604886        Random Forest   \n",
       "Overall            0.333597          0.601303              XGBoost   \n",
       "Overall            0.323296          0.604235    Gradient Boosting   \n",
       "Overall            0.326466          0.612378             LightGBM   \n",
       "Overall            0.330428          0.580456                  DNN   \n",
       "Overall            0.411252          0.618241                  FCN   \n",
       "Overall            0.242049          0.452714  Logistic Regression   \n",
       "Overall            0.216431          0.418346        Random Forest   \n",
       "Overall            0.231890          0.434700              XGBoost   \n",
       "Overall            0.227473          0.432804    Gradient Boosting   \n",
       "Overall            0.227032          0.437070             LightGBM   \n",
       "Overall            0.238516          0.412183                  DNN   \n",
       "Overall            0.299470          0.455558                  FCN   \n",
       "\n",
       "                     Subgroup  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Caste  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall       Scheduled Tribe  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall               General  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  \n",
       "Overall  Other Backward Class  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the data splits to train the models\n",
    "results = pd.DataFrame()\n",
    "for split_name, split_mask in data_splits.items():\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Training {model_name} on {split_name}...')\n",
    "        # Split the data\n",
    "        sub_X = X[split_mask]\n",
    "        sub_y = y[split_mask]\n",
    "        # Category encoding\n",
    "        sub_X = pd.get_dummies(sub_X, drop_first=True)\n",
    "        print(sub_X.shape, sub_y.shape)\n",
    "        # Convert to float32\n",
    "        sub_X = sub_X.astype('float32')\n",
    "        sub_y = sub_y.astype('float32')\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        sub_X_sd = scaler.fit_transform(sub_X)\n",
    "        sub_X = pd.DataFrame(sub_X_sd, columns=sub_X.columns, index=sub_X.index)\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(sub_X, sub_y, test_size=0.2, random_state=42)\n",
    "        # Train the model\n",
    "        if model_name in ['DNN', 'FCN']:\n",
    "            dim = X_train.shape[1]\n",
    "            model = create_dnn_model(dim) if model_name == 'DNN' else create_fcn_model(dim)\n",
    "        model_results = model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups)\n",
    "        model_results['Model'] = model_name\n",
    "        model_results['Subgroup'] = split_name\n",
    "        results = pd.concat([results, model_results], axis=0)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_subgroup_caste.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPCE Subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different data splits\n",
    "data_splits = {\n",
    "    'MPCE 1': used_data['MPCE'] == 'Lowest',\n",
    "    'MPCE 2': used_data['MPCE'] == 'Lower middle',\n",
    "    'MPCE 3': used_data['MPCE'] == 'Middle',\n",
    "    'MPCE 4': used_data['MPCE'] == 'Upper middle',\n",
    "    'MPCE 5': used_data['MPCE'] == 'Highest',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training Random Forest on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training XGBoost on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training Gradient Boosting on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training LightGBM on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "Training DNN on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 1...\n",
      "(11285, 129) (11285,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training Random Forest on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training XGBoost on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training Gradient Boosting on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training LightGBM on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "Training DNN on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 2...\n",
      "(11313, 129) (11313,)\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training Random Forest on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training XGBoost on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training Gradient Boosting on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training LightGBM on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "Training DNN on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 3...\n",
      "(11124, 129) (11124,)\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training Random Forest on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training XGBoost on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training Gradient Boosting on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training LightGBM on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "Training DNN on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 4...\n",
      "(11025, 129) (11025,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training Logistic Regression on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training Random Forest on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training XGBoost on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training Gradient Boosting on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training LightGBM on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "Training DNN on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training FCN on MPCE 5...\n",
      "(10900, 129) (10900,)\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds_tpr</th>\n",
       "      <th>equalized_odds_fpr</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>Model</th>\n",
       "      <th>Subgroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.789544</td>\n",
       "      <td>0.674952</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.597798</td>\n",
       "      <td>0.832553</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.893684</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.106316</td>\n",
       "      <td>0.231724</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.768720</td>\n",
       "      <td>0.661137</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.816576</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.762960</td>\n",
       "      <td>0.614953</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551551</td>\n",
       "      <td>0.797242</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.871169</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.128831</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.782455</td>\n",
       "      <td>0.689342</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.553230</td>\n",
       "      <td>0.828296</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.914321</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.462006</td>\n",
       "      <td>0.085679</td>\n",
       "      <td>0.195392</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.776252</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.562012</td>\n",
       "      <td>0.820882</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.893058</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.492401</td>\n",
       "      <td>0.106942</td>\n",
       "      <td>0.219318</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.743465</td>\n",
       "      <td>0.561051</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.556322</td>\n",
       "      <td>0.767323</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.822389</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.551672</td>\n",
       "      <td>0.177611</td>\n",
       "      <td>0.286664</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.731945</td>\n",
       "      <td>0.546737</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.749429</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.839275</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.471125</td>\n",
       "      <td>0.160725</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.752541</td>\n",
       "      <td>0.707169</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.675174</td>\n",
       "      <td>0.812849</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.823054</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.645949</td>\n",
       "      <td>0.176946</td>\n",
       "      <td>0.363677</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.737517</td>\n",
       "      <td>0.711724</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.794660</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.846549</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.153451</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.722492</td>\n",
       "      <td>0.664260</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.637413</td>\n",
       "      <td>0.790058</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.795154</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.612653</td>\n",
       "      <td>0.204846</td>\n",
       "      <td>0.367212</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.727756</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.662636</td>\n",
       "      <td>0.812256</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.849486</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.608213</td>\n",
       "      <td>0.150514</td>\n",
       "      <td>0.332744</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.742819</td>\n",
       "      <td>0.698137</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.658851</td>\n",
       "      <td>0.807050</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.821586</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.623751</td>\n",
       "      <td>0.178414</td>\n",
       "      <td>0.355722</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.694653</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.605993</td>\n",
       "      <td>0.612451</td>\n",
       "      <td>0.753590</td>\n",
       "      <td>0.605993</td>\n",
       "      <td>0.753304</td>\n",
       "      <td>0.605993</td>\n",
       "      <td>0.605993</td>\n",
       "      <td>0.246696</td>\n",
       "      <td>0.389748</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.690234</td>\n",
       "      <td>0.606157</td>\n",
       "      <td>0.633740</td>\n",
       "      <td>0.619642</td>\n",
       "      <td>0.745114</td>\n",
       "      <td>0.633740</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.633740</td>\n",
       "      <td>0.633740</td>\n",
       "      <td>0.272394</td>\n",
       "      <td>0.416262</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.733933</td>\n",
       "      <td>0.717262</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.709519</td>\n",
       "      <td>0.812157</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.761506</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.701942</td>\n",
       "      <td>0.238494</td>\n",
       "      <td>0.453034</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.728989</td>\n",
       "      <td>0.726405</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.694374</td>\n",
       "      <td>0.799578</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.784100</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>0.423820</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.715506</td>\n",
       "      <td>0.700708</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.686478</td>\n",
       "      <td>0.784310</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.752301</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.672816</td>\n",
       "      <td>0.247699</td>\n",
       "      <td>0.444494</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.732584</td>\n",
       "      <td>0.720365</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.705007</td>\n",
       "      <td>0.808389</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.769038</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.230962</td>\n",
       "      <td>0.443596</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.728090</td>\n",
       "      <td>0.713139</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.701529</td>\n",
       "      <td>0.804568</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.760669</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.690291</td>\n",
       "      <td>0.239331</td>\n",
       "      <td>0.448090</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.686742</td>\n",
       "      <td>0.677695</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.645653</td>\n",
       "      <td>0.753579</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.747280</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.616505</td>\n",
       "      <td>0.252720</td>\n",
       "      <td>0.421124</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.675506</td>\n",
       "      <td>0.668490</td>\n",
       "      <td>0.593204</td>\n",
       "      <td>0.628601</td>\n",
       "      <td>0.740174</td>\n",
       "      <td>0.593204</td>\n",
       "      <td>0.746444</td>\n",
       "      <td>0.593204</td>\n",
       "      <td>0.593204</td>\n",
       "      <td>0.253556</td>\n",
       "      <td>0.410787</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.736931</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.748288</td>\n",
       "      <td>0.813252</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.704265</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.295735</td>\n",
       "      <td>0.537868</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.714739</td>\n",
       "      <td>0.727909</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.725687</td>\n",
       "      <td>0.793215</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.705213</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.723478</td>\n",
       "      <td>0.294787</td>\n",
       "      <td>0.518367</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.726531</td>\n",
       "      <td>0.738865</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.735652</td>\n",
       "      <td>0.283412</td>\n",
       "      <td>0.519274</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.730612</td>\n",
       "      <td>0.739655</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.807455</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.713744</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.746087</td>\n",
       "      <td>0.286256</td>\n",
       "      <td>0.526077</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.724263</td>\n",
       "      <td>0.737719</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.734498</td>\n",
       "      <td>0.799060</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.716588</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.731304</td>\n",
       "      <td>0.283412</td>\n",
       "      <td>0.517007</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.697506</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.683478</td>\n",
       "      <td>0.702099</td>\n",
       "      <td>0.763792</td>\n",
       "      <td>0.683478</td>\n",
       "      <td>0.712796</td>\n",
       "      <td>0.683478</td>\n",
       "      <td>0.683478</td>\n",
       "      <td>0.287204</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.671655</td>\n",
       "      <td>0.676033</td>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.693220</td>\n",
       "      <td>0.732075</td>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.628436</td>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>0.548753</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.743578</td>\n",
       "      <td>0.763288</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.793955</td>\n",
       "      <td>0.819932</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.619590</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.380410</td>\n",
       "      <td>0.647248</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.745413</td>\n",
       "      <td>0.765458</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.795127</td>\n",
       "      <td>0.810982</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.624146</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.827189</td>\n",
       "      <td>0.375854</td>\n",
       "      <td>0.645413</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.727982</td>\n",
       "      <td>0.760088</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.798963</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.627563</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.372437</td>\n",
       "      <td>0.625229</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.744954</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.792692</td>\n",
       "      <td>0.822589</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.638952</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>0.361048</td>\n",
       "      <td>0.633028</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.734862</td>\n",
       "      <td>0.766176</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.782870</td>\n",
       "      <td>0.814672</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.637813</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.800307</td>\n",
       "      <td>0.362187</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.703670</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.754373</td>\n",
       "      <td>0.761173</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.617312</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.382688</td>\n",
       "      <td>0.609174</td>\n",
       "      <td>DNN</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.686239</td>\n",
       "      <td>0.734446</td>\n",
       "      <td>0.743472</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.730960</td>\n",
       "      <td>0.743472</td>\n",
       "      <td>0.601367</td>\n",
       "      <td>0.743472</td>\n",
       "      <td>0.743472</td>\n",
       "      <td>0.398633</td>\n",
       "      <td>0.604587</td>\n",
       "      <td>FCN</td>\n",
       "      <td>MPCE 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  precision    recall        f1       auc  sensitivity  \\\n",
       "Overall  0.789544   0.674952  0.536474  0.597798  0.832553     0.536474   \n",
       "Overall  0.768720   0.661137  0.424012  0.516667  0.816576     0.424012   \n",
       "Overall  0.762960   0.614953  0.500000  0.551551  0.797242     0.500000   \n",
       "Overall  0.782455   0.689342  0.462006  0.553230  0.828296     0.462006   \n",
       "Overall  0.776252   0.654545  0.492401  0.562012  0.820882     0.492401   \n",
       "Overall  0.743465   0.561051  0.551672  0.556322  0.767323     0.551672   \n",
       "Overall  0.731945   0.546737  0.471125  0.506122  0.749429     0.471125   \n",
       "Overall  0.752541   0.707169  0.645949  0.675174  0.812849     0.645949   \n",
       "Overall  0.737517   0.711724  0.572697  0.634686  0.794660     0.572697   \n",
       "Overall  0.722492   0.664260  0.612653  0.637413  0.790058     0.612653   \n",
       "Overall  0.753425   0.727756  0.608213  0.662636  0.812256     0.608213   \n",
       "Overall  0.742819   0.698137  0.623751  0.658851  0.807050     0.623751   \n",
       "Overall  0.694653   0.619048  0.605993  0.612451  0.753590     0.605993   \n",
       "Overall  0.690234   0.606157  0.633740  0.619642  0.745114     0.633740   \n",
       "Overall  0.733933   0.717262  0.701942  0.709519  0.812157     0.701942   \n",
       "Overall  0.728989   0.726405  0.665049  0.694374  0.799578     0.665049   \n",
       "Overall  0.715506   0.700708  0.672816  0.686478  0.784310     0.672816   \n",
       "Overall  0.732584   0.720365  0.690291  0.705007  0.808389     0.690291   \n",
       "Overall  0.728090   0.713139  0.690291  0.701529  0.804568     0.690291   \n",
       "Overall  0.686742   0.677695  0.616505  0.645653  0.753579     0.616505   \n",
       "Overall  0.675506   0.668490  0.593204  0.628601  0.740174     0.593204   \n",
       "Overall  0.733333   0.736931  0.760000  0.748288  0.813252     0.760000   \n",
       "Overall  0.714739   0.727909  0.723478  0.725687  0.793215     0.723478   \n",
       "Overall  0.726531   0.738865  0.735652  0.737255  0.794041     0.735652   \n",
       "Overall  0.730612   0.739655  0.746087  0.742857  0.807455     0.746087   \n",
       "Overall  0.724263   0.737719  0.731304  0.734498  0.799060     0.731304   \n",
       "Overall  0.697506   0.721763  0.683478  0.702099  0.763792     0.683478   \n",
       "Overall  0.671655   0.676033  0.711304  0.693220  0.732075     0.711304   \n",
       "Overall  0.743578   0.763288  0.827189  0.793955  0.819932     0.827189   \n",
       "Overall  0.745413   0.765458  0.827189  0.795127  0.810982     0.827189   \n",
       "Overall  0.727982   0.760088  0.795699  0.777486  0.798963     0.795699   \n",
       "Overall  0.744954   0.770290  0.816436  0.792692  0.822589     0.816436   \n",
       "Overall  0.734862   0.766176  0.800307  0.782870  0.814672     0.800307   \n",
       "Overall  0.703670   0.746988  0.761905  0.754373  0.761173     0.761905   \n",
       "Overall  0.686239   0.734446  0.743472  0.738931  0.730960     0.743472   \n",
       "\n",
       "         specificity  equal_opportunity  equalized_odds_tpr  \\\n",
       "Overall     0.893684           0.536474            0.536474   \n",
       "Overall     0.910569           0.424012            0.424012   \n",
       "Overall     0.871169           0.500000            0.500000   \n",
       "Overall     0.914321           0.462006            0.462006   \n",
       "Overall     0.893058           0.492401            0.492401   \n",
       "Overall     0.822389           0.551672            0.551672   \n",
       "Overall     0.839275           0.471125            0.471125   \n",
       "Overall     0.823054           0.645949            0.645949   \n",
       "Overall     0.846549           0.572697            0.572697   \n",
       "Overall     0.795154           0.612653            0.612653   \n",
       "Overall     0.849486           0.608213            0.608213   \n",
       "Overall     0.821586           0.623751            0.623751   \n",
       "Overall     0.753304           0.605993            0.605993   \n",
       "Overall     0.727606           0.633740            0.633740   \n",
       "Overall     0.761506           0.701942            0.701942   \n",
       "Overall     0.784100           0.665049            0.665049   \n",
       "Overall     0.752301           0.672816            0.672816   \n",
       "Overall     0.769038           0.690291            0.690291   \n",
       "Overall     0.760669           0.690291            0.690291   \n",
       "Overall     0.747280           0.616505            0.616505   \n",
       "Overall     0.746444           0.593204            0.593204   \n",
       "Overall     0.704265           0.760000            0.760000   \n",
       "Overall     0.705213           0.723478            0.723478   \n",
       "Overall     0.716588           0.735652            0.735652   \n",
       "Overall     0.713744           0.746087            0.746087   \n",
       "Overall     0.716588           0.731304            0.731304   \n",
       "Overall     0.712796           0.683478            0.683478   \n",
       "Overall     0.628436           0.711304            0.711304   \n",
       "Overall     0.619590           0.827189            0.827189   \n",
       "Overall     0.624146           0.827189            0.827189   \n",
       "Overall     0.627563           0.795699            0.795699   \n",
       "Overall     0.638952           0.816436            0.816436   \n",
       "Overall     0.637813           0.800307            0.800307   \n",
       "Overall     0.617312           0.761905            0.761905   \n",
       "Overall     0.601367           0.743472            0.743472   \n",
       "\n",
       "         equalized_odds_fpr  disparate_impact                Model Subgroup  \n",
       "Overall            0.106316          0.231724  Logistic Regression   MPCE 1  \n",
       "Overall            0.089431          0.186974        Random Forest   MPCE 1  \n",
       "Overall            0.128831          0.237040              XGBoost   MPCE 1  \n",
       "Overall            0.085679          0.195392    Gradient Boosting   MPCE 1  \n",
       "Overall            0.106942          0.219318             LightGBM   MPCE 1  \n",
       "Overall            0.177611          0.286664                  DNN   MPCE 1  \n",
       "Overall            0.160725          0.251218                  FCN   MPCE 1  \n",
       "Overall            0.176946          0.363677  Logistic Regression   MPCE 2  \n",
       "Overall            0.153451          0.320371        Random Forest   MPCE 2  \n",
       "Overall            0.204846          0.367212              XGBoost   MPCE 2  \n",
       "Overall            0.150514          0.332744    Gradient Boosting   MPCE 2  \n",
       "Overall            0.178414          0.355722             LightGBM   MPCE 2  \n",
       "Overall            0.246696          0.389748                  DNN   MPCE 2  \n",
       "Overall            0.272394          0.416262                  FCN   MPCE 2  \n",
       "Overall            0.238494          0.453034  Logistic Regression   MPCE 3  \n",
       "Overall            0.215900          0.423820        Random Forest   MPCE 3  \n",
       "Overall            0.247699          0.444494              XGBoost   MPCE 3  \n",
       "Overall            0.230962          0.443596    Gradient Boosting   MPCE 3  \n",
       "Overall            0.239331          0.448090             LightGBM   MPCE 3  \n",
       "Overall            0.252720          0.421124                  DNN   MPCE 3  \n",
       "Overall            0.253556          0.410787                  FCN   MPCE 3  \n",
       "Overall            0.295735          0.537868  Logistic Regression   MPCE 4  \n",
       "Overall            0.294787          0.518367        Random Forest   MPCE 4  \n",
       "Overall            0.283412          0.519274              XGBoost   MPCE 4  \n",
       "Overall            0.286256          0.526077    Gradient Boosting   MPCE 4  \n",
       "Overall            0.283412          0.517007             LightGBM   MPCE 4  \n",
       "Overall            0.287204          0.493878                  DNN   MPCE 4  \n",
       "Overall            0.371564          0.548753                  FCN   MPCE 4  \n",
       "Overall            0.380410          0.647248  Logistic Regression   MPCE 5  \n",
       "Overall            0.375854          0.645413        Random Forest   MPCE 5  \n",
       "Overall            0.372437          0.625229              XGBoost   MPCE 5  \n",
       "Overall            0.361048          0.633028    Gradient Boosting   MPCE 5  \n",
       "Overall            0.362187          0.623853             LightGBM   MPCE 5  \n",
       "Overall            0.382688          0.609174                  DNN   MPCE 5  \n",
       "Overall            0.398633          0.604587                  FCN   MPCE 5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the data splits to train the models\n",
    "results = pd.DataFrame()\n",
    "for split_name, split_mask in data_splits.items():\n",
    "    for model_name, model in models.items():\n",
    "        print(f'Training {model_name} on {split_name}...')\n",
    "        # Split the data\n",
    "        sub_X = X[split_mask]\n",
    "        sub_y = y[split_mask]\n",
    "        # Category encoding\n",
    "        sub_X = pd.get_dummies(sub_X, drop_first=True)\n",
    "        print(sub_X.shape, sub_y.shape)\n",
    "        # Convert to float32\n",
    "        sub_X = sub_X.astype('float32')\n",
    "        sub_y = sub_y.astype('float32')\n",
    "        # Standardization\n",
    "        scaler = StandardScaler()\n",
    "        sub_X_sd = scaler.fit_transform(sub_X)\n",
    "        sub_X = pd.DataFrame(sub_X_sd, columns=sub_X.columns, index=sub_X.index)\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(sub_X, sub_y, test_size=0.2, random_state=42)\n",
    "        # Train the model\n",
    "        if model_name in ['DNN', 'FCN']:\n",
    "            dim = X_train.shape[1]\n",
    "            model = create_dnn_model(dim) if model_name == 'DNN' else create_fcn_model(dim)\n",
    "        # Train the model\n",
    "        model_results = model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups)\n",
    "        model_results['Model'] = model_name\n",
    "        model_results['Subgroup'] = split_name\n",
    "        results = pd.concat([results, model_results], axis=0)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results = pd.DataFrame(results)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_subgroup_MPCE.csv\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmAGw7t5BUD9GIxkZk2Q0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lasi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
