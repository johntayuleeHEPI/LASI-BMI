{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For classification model\n",
    "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# For deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64867, 80)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"derived_df.csv\")\n",
    "demographic = ['age', 'gender', 'education', 'migration', 'state', 'region', 'residence', 'religion', 'martial_status', 'living_alone']\n",
    "social = ['MPCE', 'working_status', 'occupation', 'pension_amount', 'retired', 'pension', 'caste', 'public_HI', 'private_HI']\n",
    "health = ['hypertension', 'diabetes', 'cancer', 'chr_lung', 'chr_heart', 'stroke', 'bone_joint', 'psychiatric', 'hi_chole', 'chr_renal', 'incontinence', 'kidney', 'BPH', 'influenza', 'pneumococcal', 'hepa_B', 'typhoid', 'dT', 'pain', 'sleep', 'mlaria', 'dengue', 'chickungunya', 'tuberculosis', 'UTI', 'cog_score', 'depression', 'selfrated']\n",
    "############################################\n",
    "target_var = 'waist_circumference' # 'bmi_underweight', 'bmi_overweight', 'waist_circumference'\n",
    "############################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [\n",
    "    'education',\n",
    "    'state',\n",
    "    'region',\n",
    "    'religion',\n",
    "    'MPCE',\n",
    "    'working_status',\n",
    "    'occupation',\n",
    "    'caste',\n",
    "    'water',\n",
    "    'alcohol',\n",
    "    'activity1',\n",
    "    'benefit'\n",
    "    ]\n",
    "\n",
    "# Convert Type\n",
    "for col in data.columns:\n",
    "  if col in category_col:\n",
    "    data[col] = data[col].astype('category')\n",
    "  else:\n",
    "    data[col] = data[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64867 entries, 0 to 64866\n",
      "Data columns (total 80 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   age                  64867 non-null  float64 \n",
      " 1   gender               64867 non-null  float64 \n",
      " 2   education            64866 non-null  category\n",
      " 3   migration            64770 non-null  float64 \n",
      " 4   state                64867 non-null  category\n",
      " 5   region               64867 non-null  category\n",
      " 6   residence            64867 non-null  float64 \n",
      " 7   religion             64867 non-null  category\n",
      " 8   martial_status       64865 non-null  float64 \n",
      " 9   living_alone         64867 non-null  float64 \n",
      " 10  MPCE                 64865 non-null  category\n",
      " 11  working_status       64852 non-null  category\n",
      " 12  occupation           64867 non-null  category\n",
      " 13  pension_amount       64867 non-null  float64 \n",
      " 14  retired              64774 non-null  float64 \n",
      " 15  pension              64812 non-null  float64 \n",
      " 16  caste                64770 non-null  category\n",
      " 17  hhsize               64867 non-null  float64 \n",
      " 18  hh_head_female       64867 non-null  float64 \n",
      " 19  water                64867 non-null  category\n",
      " 20  water_time           64867 non-null  float64 \n",
      " 21  home_ownership       63308 non-null  float64 \n",
      " 22  hypertension         64867 non-null  float64 \n",
      " 23  diabetes             64687 non-null  float64 \n",
      " 24  cancer               64696 non-null  float64 \n",
      " 25  chr_lung             64697 non-null  float64 \n",
      " 26  chr_heart            64697 non-null  float64 \n",
      " 27  stroke               64696 non-null  float64 \n",
      " 28  bone_joint           64698 non-null  float64 \n",
      " 29  psychiatric          64688 non-null  float64 \n",
      " 30  hi_chole             64696 non-null  float64 \n",
      " 31  chr_renal            64681 non-null  float64 \n",
      " 32  incontinence         64681 non-null  float64 \n",
      " 33  kidney               64681 non-null  float64 \n",
      " 34  BPH                  64680 non-null  float64 \n",
      " 35  influenza            64040 non-null  float64 \n",
      " 36  pneumococcal         64040 non-null  float64 \n",
      " 37  hepa_B               64040 non-null  float64 \n",
      " 38  typhoid              64040 non-null  float64 \n",
      " 39  dT                   64040 non-null  float64 \n",
      " 40  pain                 64644 non-null  float64 \n",
      " 41  sleep                64649 non-null  float64 \n",
      " 42  mlaria               64658 non-null  float64 \n",
      " 43  dengue               64658 non-null  float64 \n",
      " 44  chickungunya         64658 non-null  float64 \n",
      " 45  tuberculosis         64658 non-null  float64 \n",
      " 46  UTI                  64658 non-null  float64 \n",
      " 47  cog_score            64867 non-null  float64 \n",
      " 48  depression           64867 non-null  float64 \n",
      " 49  selfrated            64655 non-null  float64 \n",
      " 50  vision_self          64686 non-null  float64 \n",
      " 51  grip                 64185 non-null  float64 \n",
      " 52  aids                 64580 non-null  float64 \n",
      " 53  adl                  64587 non-null  float64 \n",
      " 54  iadl                 64541 non-null  float64 \n",
      " 55  denture              64580 non-null  float64 \n",
      " 56  smoking              64867 non-null  float64 \n",
      " 57  smokeless            64867 non-null  float64 \n",
      " 58  alcohol              64308 non-null  category\n",
      " 59  activity1            64867 non-null  category\n",
      " 60  activity2            64275 non-null  float64 \n",
      " 61  food_avail           64304 non-null  float64 \n",
      " 62  outpatient_care      64139 non-null  float64 \n",
      " 63  inpatient_care       64152 non-null  float64 \n",
      " 64  oop_outpatient       64867 non-null  float64 \n",
      " 65  oop_inpatient        64790 non-null  float64 \n",
      " 66  public_HI            64867 non-null  float64 \n",
      " 67  private_HI           64867 non-null  float64 \n",
      " 68  decision_role        64867 non-null  float64 \n",
      " 69  grandchildren        64867 non-null  float64 \n",
      " 70  provide_FS           64867 non-null  float64 \n",
      " 71  receive_FS           64867 non-null  float64 \n",
      " 72  family_unable        64867 non-null  float64 \n",
      " 73  organization_member  64867 non-null  float64 \n",
      " 74  discrimination       64867 non-null  float64 \n",
      " 75  life_satisfaction    63764 non-null  float64 \n",
      " 76  benefit              64867 non-null  category\n",
      " 77  bmi_underweight      59071 non-null  float64 \n",
      " 78  bmi_overweight       59071 non-null  float64 \n",
      " 79  waist_circumference  59048 non-null  float64 \n",
      "dtypes: category(12), float64(68)\n",
      "memory usage: 34.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55647, 79), (55647,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_data = data.copy()\n",
    "used_data = used_data.dropna()\n",
    "# Define X and y\n",
    "X = used_data.drop(target_var, axis=1)\n",
    "y = used_data[target_var]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44517, 79), (11130, 79))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Evaluate the model\n",
    "def calculate_metric(y_true, y_pred, y_pred_prob, metric_key):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate the metrics\n",
    "    ## Accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    ## Sensitivity and specificity\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    ## Equal opportunity, equalized odds, disparate impact\n",
    "    ### Equalized Odds: 根據真實標籤（0 或 1）計算錯誤率是否相等(tpr, fpr)\n",
    "    ### Demographic Parity: 預測為陽性的比例\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0    # True positive rate\n",
    "    fpr = fp / (fp + tn) if fp + tn > 0 else 0    # False positive rate\n",
    "    equal_opportunity = tpr\n",
    "    equalized_odds_tpr = tpr\n",
    "    equalized_odds_fpr = fpr\n",
    "    ppr = (tp + fp) / (tp + fp + tn + fn) if tp + fp + tn + fn > 0 else 0    # Predicted positive rate\n",
    "    disparate_impact = ppr\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'equal_opportunity': equal_opportunity,\n",
    "        'equalized_odds_tpr': equalized_odds_tpr,\n",
    "        'equalized_odds_fpr': equalized_odds_fpr,\n",
    "        'disparate_impact': disparate_impact\n",
    "    }\n",
    "\n",
    "    return metrics[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Train the model\n",
    "def model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups):\n",
    "    # Create a pipeline\n",
    "    pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # Train the model\n",
    "    if model_name in ['DNN', 'FCN']:\n",
    "        pipeline['model'].fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "        y_pred_prob = pipeline.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    # Calculate the metrics\n",
    "    results = pd.DataFrame()\n",
    "    for group_name, group_slice in groups.items():\n",
    "        # Create a Boolean mask for the group\n",
    "        group_mask = (\n",
    "            group_slice.loc[X_test.index]  # Use the group slice\n",
    "            if group_name != 'Overall'\n",
    "            else pd.Series(True, index=X_test.index)  \n",
    "        )\n",
    "\n",
    "        y_group = y_test[group_mask]\n",
    "        y_pred_group = y_pred[group_mask]\n",
    "        y_pred_prob_group = y_pred_prob[group_mask]\n",
    "        for metric_key in metric_keys:\n",
    "            # Calculate the metric\n",
    "            metric_value = calculate_metric(y_group, y_pred_group, y_pred_prob_group, metric_key)\n",
    "            # Store the results\n",
    "            results.loc[group_name, metric_key] = metric_value\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the DNN model\n",
    "def create_dnn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
    "def create_fcn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'auc',\n",
    "    'sensitivity', 'specificity', \n",
    "    'equal_opportunity', 'equalized_odds_tpr', 'equalized_odds_fpr', 'disparate_impact'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "        'Overall': slice(None),\n",
    "        'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
    "        'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
    "        'General': X['caste'] == 'General',\n",
    "        'Other Backward Class': X['caste'] == 'Other backward class',\n",
    "        'MPCE 1': X['MPCE'] == 'Lowest',\n",
    "        'MPCE 2': X['MPCE'] == 'Lower middle',\n",
    "        'MPCE 3': X['MPCE'] == 'Middle',\n",
    "        'MPCE 4': X['MPCE'] == 'Upper middle',\n",
    "        'MPCE 5': X['MPCE'] == 'Highest',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44517, 50), (11130, 50))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D\n",
    "used_group = 'D'\n",
    "used_columns = demographic\n",
    "X_train_d = X_train[used_columns]\n",
    "X_test_d = X_test[used_columns]\n",
    "# Catgorical variables\n",
    "X_train_d = pd.get_dummies(X_train_d, drop_first=True)\n",
    "X_test_d = pd.get_dummies(X_test_d, drop_first=True)\n",
    "# remove dummy variables\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others']\n",
    "# X_train_d = X_train_d.drop(dummy_col, axis=1)\n",
    "# X_test_d = X_test_d.drop(dummy_col, axis=1)\n",
    "# Convert to float\n",
    "X_train_d = X_train_d.astype('float32')\n",
    "X_test_d = X_test_d.astype('float32')\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_d_sd = scaler.fit_transform(X_train_d)\n",
    "X_test_d_sd = scaler.transform(X_test_d)\n",
    "X_train_d = pd.DataFrame(X_train_d_sd, columns=X_train_d.columns, index=X_train_d.index)\n",
    "X_test_d = pd.DataFrame(X_test_d_sd, columns=X_test_d.columns, index=X_test_d.index)\n",
    "X_train_d.shape, X_test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': create_dnn_model(dim = X_train_d.shape[1]),\n",
    "    'FCN': create_fcn_model(dim = X_train_d.shape[1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Training the Random Forest model...\n",
      "Training the XGBoost model...\n",
      "Training the Gradient Boosting model...\n",
      "Training the LightGBM model...\n",
      "Training the DNN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Training the FCN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.711829</td>\n",
       "      <td>0.671225</td>\n",
       "      <td>0.690931</td>\n",
       "      <td>0.801268</td>\n",
       "      <td>0.671225</td>\n",
       "      <td>0.768591</td>\n",
       "      <td>0.671225</td>\n",
       "      <td>1.439816</td>\n",
       "      <td>0.433693</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Caste</th>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.599309</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>0.579299</td>\n",
       "      <td>0.795457</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>0.831395</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1.391977</td>\n",
       "      <td>0.290226</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Tribe</th>\n",
       "      <td>0.723393</td>\n",
       "      <td>0.701117</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.662269</td>\n",
       "      <td>0.795664</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>0.796384</td>\n",
       "      <td>0.627500</td>\n",
       "      <td>1.423884</td>\n",
       "      <td>0.386818</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>0.721790</td>\n",
       "      <td>0.771023</td>\n",
       "      <td>0.748896</td>\n",
       "      <td>0.759798</td>\n",
       "      <td>0.798534</td>\n",
       "      <td>0.748896</td>\n",
       "      <td>0.683176</td>\n",
       "      <td>0.748896</td>\n",
       "      <td>1.432072</td>\n",
       "      <td>0.570687</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Backward Class</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.694131</td>\n",
       "      <td>0.651483</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.785797</td>\n",
       "      <td>0.651483</td>\n",
       "      <td>0.765571</td>\n",
       "      <td>0.651483</td>\n",
       "      <td>1.417054</td>\n",
       "      <td>0.421905</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 1</th>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.553977</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>0.766699</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.792876</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>1.368097</td>\n",
       "      <td>0.320875</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 2</th>\n",
       "      <td>0.697199</td>\n",
       "      <td>0.603753</td>\n",
       "      <td>0.629459</td>\n",
       "      <td>0.616338</td>\n",
       "      <td>0.752697</td>\n",
       "      <td>0.629459</td>\n",
       "      <td>0.739855</td>\n",
       "      <td>0.629459</td>\n",
       "      <td>1.369314</td>\n",
       "      <td>0.402846</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 3</th>\n",
       "      <td>0.680458</td>\n",
       "      <td>0.640758</td>\n",
       "      <td>0.660802</td>\n",
       "      <td>0.650626</td>\n",
       "      <td>0.750016</td>\n",
       "      <td>0.660802</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>0.660802</td>\n",
       "      <td>1.357359</td>\n",
       "      <td>0.464349</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 4</th>\n",
       "      <td>0.705650</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.726829</td>\n",
       "      <td>0.754135</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.700880</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>1.410404</td>\n",
       "      <td>0.525624</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 5</th>\n",
       "      <td>0.697936</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>0.746057</td>\n",
       "      <td>0.761295</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>0.642942</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>1.376844</td>\n",
       "      <td>0.584897</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy  precision    recall        f1       auc  \\\n",
       "Overall               0.723810   0.711829  0.671225  0.690931  0.801268   \n",
       "Scheduled Caste       0.747368   0.599309  0.560582  0.579299  0.795457   \n",
       "Scheduled Tribe       0.723393   0.701117  0.627500  0.662269  0.795664   \n",
       "General               0.721790   0.771023  0.748896  0.759798  0.798534   \n",
       "Other Backward Class  0.714286   0.694131  0.651483  0.672131  0.785797   \n",
       "...                        ...        ...       ...       ...       ...   \n",
       "MPCE 1                0.725615   0.553977  0.575221  0.564399  0.766699   \n",
       "MPCE 2                0.697199   0.603753  0.629459  0.616338  0.752697   \n",
       "MPCE 3                0.680458   0.640758  0.660802  0.650626  0.750016   \n",
       "MPCE 4                0.705650   0.745000  0.709524  0.726829  0.754135   \n",
       "MPCE 5                0.697936   0.758621  0.733902  0.746057  0.761295   \n",
       "\n",
       "                      sensitivity  specificity  equal_opportunity  \\\n",
       "Overall                  0.671225     0.768591           0.671225   \n",
       "Scheduled Caste          0.560582     0.831395           0.560582   \n",
       "Scheduled Tribe          0.627500     0.796384           0.627500   \n",
       "General                  0.748896     0.683176           0.748896   \n",
       "Other Backward Class     0.651483     0.765571           0.651483   \n",
       "...                           ...          ...                ...   \n",
       "MPCE 1                   0.575221     0.792876           0.575221   \n",
       "MPCE 2                   0.629459     0.739855           0.629459   \n",
       "MPCE 3                   0.660802     0.696557           0.660802   \n",
       "MPCE 4                   0.709524     0.700880           0.709524   \n",
       "MPCE 5                   0.733902     0.642942           0.733902   \n",
       "\n",
       "                      equalized_odds  disparate_impact                model  \n",
       "Overall                     1.439816          0.433693  Logistic Regression  \n",
       "Scheduled Caste             1.391977          0.290226  Logistic Regression  \n",
       "Scheduled Tribe             1.423884          0.386818  Logistic Regression  \n",
       "General                     1.432072          0.570687  Logistic Regression  \n",
       "Other Backward Class        1.417054          0.421905  Logistic Regression  \n",
       "...                              ...               ...                  ...  \n",
       "MPCE 1                      1.368097          0.320875                  FCN  \n",
       "MPCE 2                      1.369314          0.402846                  FCN  \n",
       "MPCE 3                      1.357359          0.464349                  FCN  \n",
       "MPCE 4                      1.410404          0.525624                  FCN  \n",
       "MPCE 5                      1.376844          0.584897                  FCN  \n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "results = pd.DataFrame()\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training the {model_name} model...\")\n",
    "    model_results = model_fitted(model_name, model, X_train_d, y_train, X_test_d, y_test, metric_keys, groups)\n",
    "    model_results['model'] = model_name\n",
    "    results = pd.concat([results, model_results])\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_{used_group}.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic data + Socialeconomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44517, 67), (11130, 67))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DS\n",
    "used_group = 'DS'\n",
    "used_columns = demographic + social\n",
    "X_train_ds = X_train[used_columns]\n",
    "X_test_ds = X_test[used_columns]\n",
    "# Catgorical variables\n",
    "X_train_ds = pd.get_dummies(X_train_ds, drop_first=True)\n",
    "X_test_ds = pd.get_dummies(X_test_ds, drop_first=True)\n",
    "# remove dummy variables\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General']\n",
    "# X_train_ds = X_train_ds.drop(dummy_col, axis=1)\n",
    "# X_test_ds = X_test_ds.drop(dummy_col, axis=1)\n",
    "# Convert to float\n",
    "X_train_ds = X_train_ds.astype('float32')\n",
    "X_test_ds = X_test_ds.astype('float32')\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_ds_sd = scaler.fit_transform(X_train_ds)\n",
    "X_test_ds_sd = scaler.transform(X_test_ds)\n",
    "X_train_ds = pd.DataFrame(X_train_ds_sd, columns=X_train_ds.columns, index=X_train_ds.index)\n",
    "X_test_ds = pd.DataFrame(X_test_ds_sd, columns=X_test_ds.columns, index=X_test_ds.index)\n",
    "X_train_ds.shape, X_test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': create_dnn_model(dim = X_train_ds.shape[1]),\n",
    "    'FCN': create_fcn_model(dim = X_train_ds.shape[1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Training the Random Forest model...\n",
      "Training the XGBoost model...\n",
      "Training the Gradient Boosting model...\n",
      "Training the LightGBM model...\n",
      "Training the DNN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step\n",
      "Training the FCN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.734501</td>\n",
       "      <td>0.723461</td>\n",
       "      <td>0.684313</td>\n",
       "      <td>0.703343</td>\n",
       "      <td>0.810628</td>\n",
       "      <td>0.684313</td>\n",
       "      <td>0.777242</td>\n",
       "      <td>0.684313</td>\n",
       "      <td>1.461555</td>\n",
       "      <td>0.435040</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Caste</th>\n",
       "      <td>0.763910</td>\n",
       "      <td>0.668950</td>\n",
       "      <td>0.473344</td>\n",
       "      <td>0.554399</td>\n",
       "      <td>0.806230</td>\n",
       "      <td>0.473344</td>\n",
       "      <td>0.894622</td>\n",
       "      <td>0.473344</td>\n",
       "      <td>1.367966</td>\n",
       "      <td>0.219549</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Tribe</th>\n",
       "      <td>0.733657</td>\n",
       "      <td>0.732929</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>0.662097</td>\n",
       "      <td>0.797733</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>0.832540</td>\n",
       "      <td>0.603750</td>\n",
       "      <td>1.436290</td>\n",
       "      <td>0.356024</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>0.738327</td>\n",
       "      <td>0.763503</td>\n",
       "      <td>0.803532</td>\n",
       "      <td>0.783006</td>\n",
       "      <td>0.807315</td>\n",
       "      <td>0.803532</td>\n",
       "      <td>0.645440</td>\n",
       "      <td>0.803532</td>\n",
       "      <td>1.448972</td>\n",
       "      <td>0.618353</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Backward Class</th>\n",
       "      <td>0.718095</td>\n",
       "      <td>0.691513</td>\n",
       "      <td>0.673199</td>\n",
       "      <td>0.682233</td>\n",
       "      <td>0.794822</td>\n",
       "      <td>0.673199</td>\n",
       "      <td>0.754758</td>\n",
       "      <td>0.673199</td>\n",
       "      <td>1.427957</td>\n",
       "      <td>0.437619</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 1</th>\n",
       "      <td>0.705561</td>\n",
       "      <td>0.523881</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.520772</td>\n",
       "      <td>0.725932</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>1.307277</td>\n",
       "      <td>0.305378</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 2</th>\n",
       "      <td>0.663851</td>\n",
       "      <td>0.563986</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.568493</td>\n",
       "      <td>0.702157</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>0.721014</td>\n",
       "      <td>0.573072</td>\n",
       "      <td>1.294087</td>\n",
       "      <td>0.392619</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 3</th>\n",
       "      <td>0.666373</td>\n",
       "      <td>0.626070</td>\n",
       "      <td>0.643206</td>\n",
       "      <td>0.634523</td>\n",
       "      <td>0.718655</td>\n",
       "      <td>0.643206</td>\n",
       "      <td>0.685348</td>\n",
       "      <td>0.643206</td>\n",
       "      <td>1.328555</td>\n",
       "      <td>0.462588</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 4</th>\n",
       "      <td>0.667105</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.727727</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.657869</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>1.332472</td>\n",
       "      <td>0.525624</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 5</th>\n",
       "      <td>0.675422</td>\n",
       "      <td>0.720947</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>0.737879</td>\n",
       "      <td>0.729761</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>0.552788</td>\n",
       "      <td>0.755625</td>\n",
       "      <td>1.308412</td>\n",
       "      <td>0.633677</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy  precision    recall        f1       auc  \\\n",
       "Overall               0.734501   0.723461  0.684313  0.703343  0.810628   \n",
       "Scheduled Caste       0.763910   0.668950  0.473344  0.554399  0.806230   \n",
       "Scheduled Tribe       0.733657   0.732929  0.603750  0.662097  0.797733   \n",
       "General               0.738327   0.763503  0.803532  0.783006  0.807315   \n",
       "Other Backward Class  0.718095   0.691513  0.673199  0.682233  0.794822   \n",
       "...                        ...        ...       ...       ...       ...   \n",
       "MPCE 1                0.705561   0.523881  0.517699  0.520772  0.725932   \n",
       "MPCE 2                0.663851   0.563986  0.573072  0.568493  0.702157   \n",
       "MPCE 3                0.666373   0.626070  0.643206  0.634523  0.718655   \n",
       "MPCE 4                0.667105   0.708333  0.674603  0.691057  0.727727   \n",
       "MPCE 5                0.675422   0.720947  0.755625  0.737879  0.729761   \n",
       "\n",
       "                      sensitivity  specificity  equal_opportunity  \\\n",
       "Overall                  0.684313     0.777242           0.684313   \n",
       "Scheduled Caste          0.473344     0.894622           0.473344   \n",
       "Scheduled Tribe          0.603750     0.832540           0.603750   \n",
       "General                  0.803532     0.645440           0.803532   \n",
       "Other Backward Class     0.673199     0.754758           0.673199   \n",
       "...                           ...          ...                ...   \n",
       "MPCE 1                   0.517699     0.789578           0.517699   \n",
       "MPCE 2                   0.573072     0.721014           0.573072   \n",
       "MPCE 3                   0.643206     0.685348           0.643206   \n",
       "MPCE 4                   0.674603     0.657869           0.674603   \n",
       "MPCE 5                   0.755625     0.552788           0.755625   \n",
       "\n",
       "                      equalized_odds  disparate_impact                model  \n",
       "Overall                     1.461555          0.435040  Logistic Regression  \n",
       "Scheduled Caste             1.367966          0.219549  Logistic Regression  \n",
       "Scheduled Tribe             1.436290          0.356024  Logistic Regression  \n",
       "General                     1.448972          0.618353  Logistic Regression  \n",
       "Other Backward Class        1.427957          0.437619  Logistic Regression  \n",
       "...                              ...               ...                  ...  \n",
       "MPCE 1                      1.307277          0.305378                  FCN  \n",
       "MPCE 2                      1.294087          0.392619                  FCN  \n",
       "MPCE 3                      1.328555          0.462588                  FCN  \n",
       "MPCE 4                      1.332472          0.525624                  FCN  \n",
       "MPCE 5                      1.308412          0.633677                  FCN  \n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "results = pd.DataFrame()\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training the {model_name} model...\")\n",
    "    model_results = model_fitted(model_name, model, X_train_ds, y_train, X_test_ds, y_test, metric_keys, groups)\n",
    "    model_results['model'] = model_name\n",
    "    results = pd.concat([results, model_results])\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_{used_group}.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic data + Socialeconomic data + Health data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44517, 95), (11130, 95))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DSH\n",
    "used_group = 'DSH'\n",
    "used_columns = demographic + social + health\n",
    "X_train_dsh = X_train[used_columns]\n",
    "X_test_dsh = X_test[used_columns]\n",
    "# Catgorical variables\n",
    "X_train_dsh = pd.get_dummies(X_train_dsh, drop_first=True)\n",
    "X_test_dsh = pd.get_dummies(X_test_dsh, drop_first=True)\n",
    "# remove dummy variables\n",
    "# dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General']\n",
    "# X_train_dsh = X_train_dsh.drop(dummy_col, axis=1)\n",
    "# X_test_dsh = X_test_dsh.drop(dummy_col, axis=1)\n",
    "# Convert to float\n",
    "X_train_dsh = X_train_dsh.astype('float32')\n",
    "X_test_dsh = X_test_dsh.astype('float32')\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_dsh_sd = scaler.fit_transform(X_train_dsh)\n",
    "X_test_dsh_sd = scaler.transform(X_test_dsh)\n",
    "X_train_dsh = pd.DataFrame(X_train_dsh_sd, columns=X_train_dsh.columns, index=X_train_dsh.index)\n",
    "X_test_dsh = pd.DataFrame(X_test_dsh_sd, columns=X_test_dsh.columns, index=X_test_dsh.index)\n",
    "X_train_dsh.shape, X_test_dsh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': create_dnn_model(dim = X_train_dsh.shape[1]),\n",
    "    'FCN': create_fcn_model(dim = X_train_dsh.shape[1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Training the Random Forest model...\n",
      "Training the XGBoost model...\n",
      "Training the Gradient Boosting model...\n",
      "Training the LightGBM model...\n",
      "Training the DNN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step\n",
      "Training the FCN model...\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>equal_opportunity</th>\n",
       "      <th>equalized_odds</th>\n",
       "      <th>disparate_impact</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overall</th>\n",
       "      <td>0.748697</td>\n",
       "      <td>0.738791</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>0.719768</td>\n",
       "      <td>0.826143</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>0.788721</td>\n",
       "      <td>0.701700</td>\n",
       "      <td>1.490420</td>\n",
       "      <td>0.436837</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Caste</th>\n",
       "      <td>0.766416</td>\n",
       "      <td>0.665227</td>\n",
       "      <td>0.497577</td>\n",
       "      <td>0.569316</td>\n",
       "      <td>0.810806</td>\n",
       "      <td>0.497577</td>\n",
       "      <td>0.887355</td>\n",
       "      <td>0.497577</td>\n",
       "      <td>1.384931</td>\n",
       "      <td>0.232080</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scheduled Tribe</th>\n",
       "      <td>0.742301</td>\n",
       "      <td>0.742129</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>0.811230</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.836346</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>1.455096</td>\n",
       "      <td>0.360346</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General</th>\n",
       "      <td>0.747406</td>\n",
       "      <td>0.771129</td>\n",
       "      <td>0.810706</td>\n",
       "      <td>0.790422</td>\n",
       "      <td>0.823006</td>\n",
       "      <td>0.810706</td>\n",
       "      <td>0.657233</td>\n",
       "      <td>0.810706</td>\n",
       "      <td>1.467939</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Backward Class</th>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.722496</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.710633</td>\n",
       "      <td>0.818420</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>0.780709</td>\n",
       "      <td>0.699153</td>\n",
       "      <td>1.479862</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 1</th>\n",
       "      <td>0.699180</td>\n",
       "      <td>0.513433</td>\n",
       "      <td>0.507375</td>\n",
       "      <td>0.510386</td>\n",
       "      <td>0.696618</td>\n",
       "      <td>0.507375</td>\n",
       "      <td>0.784960</td>\n",
       "      <td>0.507375</td>\n",
       "      <td>1.292335</td>\n",
       "      <td>0.305378</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 2</th>\n",
       "      <td>0.661627</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.559264</td>\n",
       "      <td>0.560877</td>\n",
       "      <td>0.698847</td>\n",
       "      <td>0.559264</td>\n",
       "      <td>0.726087</td>\n",
       "      <td>0.559264</td>\n",
       "      <td>1.285350</td>\n",
       "      <td>0.384171</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 3</th>\n",
       "      <td>0.670335</td>\n",
       "      <td>0.624319</td>\n",
       "      <td>0.672532</td>\n",
       "      <td>0.647529</td>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.672532</td>\n",
       "      <td>0.668535</td>\n",
       "      <td>0.672532</td>\n",
       "      <td>1.341067</td>\n",
       "      <td>0.485035</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 4</th>\n",
       "      <td>0.664477</td>\n",
       "      <td>0.705150</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.689123</td>\n",
       "      <td>0.723257</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>0.652981</td>\n",
       "      <td>0.673810</td>\n",
       "      <td>1.326791</td>\n",
       "      <td>0.527376</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPCE 5</th>\n",
       "      <td>0.668386</td>\n",
       "      <td>0.713343</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>0.733509</td>\n",
       "      <td>0.725304</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>0.536180</td>\n",
       "      <td>0.754849</td>\n",
       "      <td>1.291029</td>\n",
       "      <td>0.639775</td>\n",
       "      <td>FCN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy  precision    recall        f1       auc  \\\n",
       "Overall               0.748697   0.738791  0.701700  0.719768  0.826143   \n",
       "Scheduled Caste       0.766416   0.665227  0.497577  0.569316  0.810806   \n",
       "Scheduled Tribe       0.742301   0.742129  0.618750  0.674847  0.811230   \n",
       "General               0.747406   0.771129  0.810706  0.790422  0.823006   \n",
       "Other Backward Class  0.744048   0.722496  0.699153  0.710633  0.818420   \n",
       "...                        ...        ...       ...       ...       ...   \n",
       "MPCE 1                0.699180   0.513433  0.507375  0.510386  0.696618   \n",
       "MPCE 2                0.661627   0.562500  0.559264  0.560877  0.698847   \n",
       "MPCE 3                0.670335   0.624319  0.672532  0.647529  0.726646   \n",
       "MPCE 4                0.664477   0.705150  0.673810  0.689123  0.723257   \n",
       "MPCE 5                0.668386   0.713343  0.754849  0.733509  0.725304   \n",
       "\n",
       "                      sensitivity  specificity  equal_opportunity  \\\n",
       "Overall                  0.701700     0.788721           0.701700   \n",
       "Scheduled Caste          0.497577     0.887355           0.497577   \n",
       "Scheduled Tribe          0.618750     0.836346           0.618750   \n",
       "General                  0.810706     0.657233           0.810706   \n",
       "Other Backward Class     0.699153     0.780709           0.699153   \n",
       "...                           ...          ...                ...   \n",
       "MPCE 1                   0.507375     0.784960           0.507375   \n",
       "MPCE 2                   0.559264     0.726087           0.559264   \n",
       "MPCE 3                   0.672532     0.668535           0.672532   \n",
       "MPCE 4                   0.673810     0.652981           0.673810   \n",
       "MPCE 5                   0.754849     0.536180           0.754849   \n",
       "\n",
       "                      equalized_odds  disparate_impact                model  \n",
       "Overall                     1.490420          0.436837  Logistic Regression  \n",
       "Scheduled Caste             1.384931          0.232080  Logistic Regression  \n",
       "Scheduled Tribe             1.455096          0.360346  Logistic Regression  \n",
       "General                     1.467939          0.617704  Logistic Regression  \n",
       "Other Backward Class        1.479862          0.435000  Logistic Regression  \n",
       "...                              ...               ...                  ...  \n",
       "MPCE 1                      1.292335          0.305378                  FCN  \n",
       "MPCE 2                      1.285350          0.384171                  FCN  \n",
       "MPCE 3                      1.341067          0.485035                  FCN  \n",
       "MPCE 4                      1.326791          0.527376                  FCN  \n",
       "MPCE 5                      1.291029          0.639775                  FCN  \n",
       "\n",
       "[70 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "results = pd.DataFrame()\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training the {model_name} model...\")\n",
    "    model_results = model_fitted(model_name, model, X_train_dsh, y_train, X_test_dsh, y_test, metric_keys, groups)\n",
    "    model_results['model'] = model_name\n",
    "    results = pd.concat([results, model_results])\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_{used_group}.csv\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmAGw7t5BUD9GIxkZk2Q0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lasi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
