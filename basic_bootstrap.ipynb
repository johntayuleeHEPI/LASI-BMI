{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uphKROdaubVc"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19494,
     "status": "ok",
     "timestamp": 1727249529680,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "nigCUKn8tcnt",
    "outputId": "1b036919-c84c-4c5d-f9ee-534e5803859b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For classification model\n",
    "# 'lr', 'rf', 'lightgbm', 'gbc', 'xgboost'\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# For deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1727249532066,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "9NAdT4W0tuxB"
   },
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working directory\n",
    "os.chdir('C:\\\\Users\\\\h2408\\\\Downloads\\\\RA\\\\1_paper_LASI\\\\data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"derived_df.csv\")\n",
    "\n",
    "# Drop the target variables of other papers\n",
    "target_vars = ['bmi_underweight', 'bmi_overweight', 'waist_circumference']\n",
    "######################################\n",
    "target_var = 'waist_circumference'\n",
    "######################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col = [\n",
    "    'education',\n",
    "    'state',\n",
    "    'region',\n",
    "    'religion',\n",
    "    'MPCE',\n",
    "    'working_status',\n",
    "    'occupation',\n",
    "    'caste',\n",
    "    'water',\n",
    "    'alcohol',\n",
    "    'activity1',\n",
    "    'benefit'\n",
    "    ]\n",
    "\n",
    "# Convert Type\n",
    "for col in data.columns:\n",
    "  if col in category_col:\n",
    "    data[col] = data[col].astype('category')\n",
    "  else:\n",
    "    data[col] = data[col].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_data = data.copy()\n",
    "# Drop the missing values\n",
    "used_data = used_data.dropna()\n",
    "# Define X and y\n",
    "X = used_data.drop(target_vars, axis=1)\n",
    "y = used_data[target_var]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "        'Overall': slice(None),\n",
    "        'Scheduled Caste': X['caste'] == 'Scheduled caste',\n",
    "        'Scheduled Tribe': X['caste'] == 'Scheduled tribe',\n",
    "        'General': X['caste'] == 'General',\n",
    "        'Other Backward Class': X['caste'] == 'Other backward class',\n",
    "        'MPCE 1': X['MPCE'] == 'Lowest',\n",
    "        'MPCE 2': X['MPCE'] == 'Lower middle',\n",
    "        'MPCE 3': X['MPCE'] == 'Middle',\n",
    "        'MPCE 4': X['MPCE'] == 'Upper middle',\n",
    "        'MPCE 5': X['MPCE'] == 'Highest',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1727249624171,
     "user": {
      "displayName": "Nick Chen",
      "userId": "17776654295019992426"
     },
     "user_tz": -480
    },
    "id": "IXd2o2uzt8YM",
    "outputId": "1578e436-fd15-4bf6-a2b8-29e0eddd0618"
   },
   "outputs": [],
   "source": [
    "# Category encoding\n",
    "X = pd.get_dummies(X)\n",
    "dummy_col = ['education_No', 'state_Chandigarh', 'region_Central', 'religion_Others', 'MPCE_Middle', 'working_status_Never worked', 'occupation_Currently no work', 'caste_General', 'water_other', 'alcohol_abstainer', 'activity1_moderate', 'benefit_non-applicable']\n",
    "X = X.drop(dummy_col, axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_sd = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_sd, columns=X.columns, index=X.index)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Evaluate the model\n",
    "def calculate_metric(y_true, y_pred, y_pred_prob, metric_key):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate the metrics\n",
    "    ## Accuracy, precision, recall, f1, auc\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_prob)\n",
    "    ## Sensitivity and specificity\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    ## Equal opportunity, equalized odds, disparate impact\n",
    "    ### Equalized Odds: 根據真實標籤（0 或 1）計算錯誤率是否相等(tpr, fpr)\n",
    "    ### Demographic Parity: 預測為陽性的比例\n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else 0    # True positive rate\n",
    "    fpr = fp / (fp + tn) if fp + tn > 0 else 0    # False positive rate\n",
    "    equal_opportunity = tpr\n",
    "    equalized_odds_tpr = tpr\n",
    "    equalized_odds_fpr = fpr\n",
    "    ppr = (tp + fp) / (tp + fp + tn + fn) if tp + fp + tn + fn > 0 else 0    # Predicted positive rate\n",
    "    disparate_impact = ppr\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'equal_opportunity': equal_opportunity,\n",
    "        'equalized_odds_tpr': equalized_odds_tpr,\n",
    "        'equalized_odds_fpr': equalized_odds_fpr,\n",
    "        'disparate_impact': disparate_impact\n",
    "    }\n",
    "\n",
    "    return metrics[metric_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Calculate the confidence interval\n",
    "def calculate_ci(y_true, y_pred, y_pred_prob, metric_keys, n_resamples=1000, ci=0.95, seed=42):\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Bootstrap resampling\n",
    "    resample_metrics = {metric_key: [] for metric_key in metric_keys}\n",
    "    for _ in range(n_resamples):\n",
    "        for metric_key in metric_keys:\n",
    "            # Resample the data with replacement\n",
    "            resampled_y_true, resampled_y_pred, resampled_y_pred_prob = resample(y_true, y_pred, y_pred_prob)\n",
    "            # Calculate the metric for the resampled data\n",
    "            resampled_metric = calculate_metric(resampled_y_true, resampled_y_pred, resampled_y_pred_prob, metric_key)\n",
    "\n",
    "            resample_metrics[metric_key].append(resampled_metric)\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    ci_metrics = {}\n",
    "    for metric_key in metric_keys:\n",
    "        resample_metric = resample_metrics[metric_key]\n",
    "        ci_mean = np.mean(resample_metric)\n",
    "        lower_bound = np.percentile(resample_metric, (1 - ci) / 2 * 100)\n",
    "        upper_bound = np.percentile(resample_metric, (1 + ci) / 2 * 100)\n",
    "\n",
    "        # mean, lower_bound, upper_bound\n",
    "        ci_metrics[metric_key] = (ci_mean, lower_bound, upper_bound)\n",
    "        \n",
    "    return ci_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Train the model\n",
    "def model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups):\n",
    "   \n",
    "    # Train the model\n",
    "    if model_name in ['DNN', 'FCN']:\n",
    "        model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "        y_pred_prob = model.predict(X_test).ravel()\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "    # Calculate the metrics\n",
    "    results = pd.DataFrame()\n",
    "    for group_name, group_slice in groups.items():\n",
    "        # Create a Boolean mask for the group\n",
    "        group_mask = (\n",
    "            group_slice.loc[X_test.index]  # Use the group slice\n",
    "            if group_name != 'Overall'\n",
    "            else pd.Series(True, index=X_test.index)  \n",
    "        )\n",
    "\n",
    "        y_group = y_test[group_mask]\n",
    "        y_pred_group = y_pred[group_mask]\n",
    "        y_pred_prob_group = y_pred_prob[group_mask]\n",
    "\n",
    "        # Calculate the CI\n",
    "        # ci_metrics = calculate_ci(y_group, y_pred_group, y_pred_prob_group, metric_keys)\n",
    "        for metric_key in metric_keys:\n",
    "            # Calculate the metric\n",
    "            metric_value = calculate_metric(y_group, y_pred_group, y_pred_prob_group, metric_key)\n",
    "            # ci_mean, ci_lower_bound, ci_upper_bound = ci_metrics[metric_key]\n",
    "            # Store the results\n",
    "            results.loc[group_name, metric_key] = metric_value\n",
    "            # results.loc[group_name, f'{metric_key}_cilow'] = ci_lower_bound\n",
    "            # results.loc[group_name, f'{metric_key}_ciup'] = ci_upper_bound\n",
    "            # results.loc[group_name, f'{metric_key}_ci'] = f'{ci_mean:.2f} ({ci_lower_bound:.2f}-{ci_upper_bound:.2f})'\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the DNN model\n",
    "def create_dnn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Define the function to create the Fully Connected Network (FCN) model\n",
    "def create_fcn_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=dim, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "    # Compile the model with AUROC as a metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[AUC(name='auroc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5QAqXEpxKBe"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Gradient Boosting\n",
    "5. LightGBM\n",
    "6. DNN\n",
    "7. FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_keys = [\n",
    "    'accuracy', 'precision', 'recall', 'f1', 'auc',\n",
    "    'sensitivity', 'specificity', \n",
    "    'equal_opportunity', 'equalized_odds_tpr', 'equalized_odds_fpr', 'disparate_impact'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, force_row_wise=True, verbose=-1),\n",
    "    'DNN': create_dnn_model(dim = X_train.shape[1]),\n",
    "    'FCN': create_fcn_model(dim = X_train.shape[1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the models\n",
    "results = pd.DataFrame()\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training the {model_name} model...\")\n",
    "    model_results = model_fitted(model_name, model, X_train, y_train, X_test, y_test, metric_keys, groups)\n",
    "    model_results['model'] = model_name\n",
    "    results = pd.concat([results, model_results])\n",
    "# results.to_csv(f\"{target_var}\\\\results_standardized.csv\", index=True)\n",
    "results.to_csv(f\"standardized\\\\{target_var}\\\\results_woci.csv\", index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use cross-validation to evaluate the models\n",
    "# results = pd.DataFrame()\n",
    "# for model_name, model in models.items():\n",
    "#     cv_scores = model_cv(model_name, model, X, y, groups)\n",
    "#     cv_scores['model'] = model_name\n",
    "#     results = pd.concat([results, cv_scores])\n",
    "# results = pd.DataFrame(results)\n",
    "# results.to_csv(f\"{target_var}\\\\cvresults.csv\")\n",
    "# results"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNmAGw7t5BUD9GIxkZk2Q0Q",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lasi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
